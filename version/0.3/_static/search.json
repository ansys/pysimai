[{"objectID":"Home","href":"_examples/01_pysimai_ex/index.html#pysimai-utilities","title":"PySimAI utilities","text":"PySimAI utilities\n\nThis section provides a collection of practical script examples illustrating SimAI functionalities and use cases.\nThey serve as a reference guide for users to implement similar solutions in their projects.\n\nsphx_glr__examples_01_pysimai_ex_00-model_configuration_reuse.py\n\nsphx_glr__examples_01_pysimai_ex_01-model_recomputation.py\n\nsphx_glr__examples_01_pysimai_ex_02-subset_assignment.py\n\nsphx_glr__examples_01_pysimai_ex_03-list_based_subset_assignment.py\n\n"},{"objectID":"Home","href":"_examples/01_pysimai_ex/03-list_based_subset_assignment.html#list-based-subset-assignment","title":"List-based subset assignment","text":"List-based subset assignment\n\nThis example demonstrates how to distribute your dataset between Test\nand Training subsets using lists."},{"objectID":"Home","href":"_examples/01_pysimai_ex/03-list_based_subset_assignment.html#import-necessary-libraries","title":"List-based subset assignment > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/01_pysimai_ex/03-list_based_subset_assignment.html#create-lists","title":"List-based subset assignment > Create lists","text":"Create lists\n\nList the data to be used for the test set."},{"objectID":"Home","href":"_examples/01_pysimai_ex/03-list_based_subset_assignment.html#connect-to-the-platform","title":"List-based subset assignment > Connect to the platform","text":"Connect to the platform\n\nConnect to the SimAI platform. Refer to the anchor-credentials\nsection of the documentation to adapt the connection type."},{"objectID":"Home","href":"_examples/01_pysimai_ex/03-list_based_subset_assignment.html#assign-subsets","title":"List-based subset assignment > Assign subsets","text":"Assign subsets\n\nAssign a subset to each dataset (list) you created.\n\n\n\nDownload Jupyter notebook: 03-list_based_subset_assignment.ipynb\n\nDownload Python source code: 03-list_based_subset_assignment.py\n\nDownload zipped: 03-list_based_subset_assignment.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"API reference","href":"api_reference/selections.html#selections","title":"API reference > Selections","text":"Selections"},{"objectID":"API reference","href":"api_reference/selections.html#selection-basics","title":"API reference > Selections > Selection basics","text":"Selection basics\n\n\n\nThe Selection class allows you\nto run a large number of operations in parallel by manipulating whole collections of SimAI models\n(Geometries,\nPredictions, and\nPost-Processings instances).\n\nYou create a selection by combining a list of Geometry\ninstances with a list of Scalars instances:\n\nThe resulting selection contains all possible combinations between the geometries and\nscalars. Each of those combinations is a Point\ninstance, which can be viewed as a potential Prediction\ninstance.\n\nAt first, all predictions may not exist. However, you can use the run_predictions()\nmethod to run them:"},{"objectID":"API reference","href":"api_reference/selections.html#selection-api-reference","title":"API reference > Selections > Selection API reference","text":"Selection API reference\n\nIn essence, a Selection instance is a\ncollection of points instances.\n\n\n\nclass Point\n\nProvides a Point object, where a prediction can be run.\n\nA point is at the intersection of a Geometry\nisstance and Scalars instance.\n\n\n\n\n\nrun_prediction(scalars: Dict[str, Number] | None = None, boundary_conditions: Dict[str, Number] | None = None)\n\nRun the prediction on the geometry for this scalar.\n\n\n\n\n\nproperty boundary_conditions: Dict[str, Number]\n\n(Deprecated) BoundaryConditions object for the Point\ninstance.\n\n\n\nproperty geometry: Geometry\n\nGeometry object for the Point instance.\n\n\n\nproperty prediction: Prediction | None\n\nPrediction instance\ncorresponding to the point or None if no prediction has yet been run.\n\n\n\nproperty scalars: Dict[str, Number]\n\nScalars object for the Point\ninstance.\n\n\n\nclass Selection\n\nProvides a Selection object, which is a collection of Points instances.\n\nSelections are built from a list of Geometries\ninstances and a list of Scalars instances.\n\nThe resulting selection contains all combinations between the geometries\nand the scalars.\n\nParameters\n\ngeometries (Geometry | List[Geometry]) – Geometries to include in the selection.\n\nscalars (Dict[str, Number] | List[Dict[str, Number]] | None) – Scalars to include in the selection.\n\ntolerance (float | None) – Optional delta to apply to scalar equality.\nThe default is 10**-6. If the difference between two boundary\nconditions is lower than the tolerance, the two scalars\nare considered as equal.\n\n\n\nget_runnable_predictions() -> List[Point]\n\nList of all Points instances in the selection where predictions haven’t\nbeen run yet.\n\n\n\n\n\nreload() -> None\n\nRefreshes the predictions in the selection.\n\nThis method loads any predictions run from another session and\nremoves possible deleted predictions.\n\n\n\n\n\nrun_predictions() -> None\n\nRun all missing predictions in the selection.\n\n\n\n\n\nwait() -> None\n\nWait for all ongoing operations (predictions and postprocessings)\nin the selection to finish.\n\nRaises\n\nansys.simai.core.errors.SimAIError – If a single error occurred when computing this selection’s operations.\n\nansys.simai.core.errors.MultipleErrors – If multiple exceptions occurred when computing this selection’s operations.\n\n\n\nproperty boundary_conditions: List[Dict[str, Number]]\n\n(Deprecated) List of all existing Boundary conditions\ninstances in the selection.\n\n\n\nproperty geometries: List[Geometry]\n\nList of all existing Geometries\ninstances in the selection.\n\n\n\nproperty points: List[Point]\n\nList of all Points instances in the selection.\n\n\n\nproperty points_with_prediction: List[Point | None]\n\nList of all Points instances in the selection where predictions exist.\n\n\n\nproperty points_without_prediction: List[Point | None]\n\nList of all Points instances in the selection where predictions don’t exist.\n\n\n\nproperty post: SelectionPostProcessingsMethods\n\nNamespace containing methods to access and run postprocessings\nfor the predictions in the selection.\n\nFor more information, see the SelectionPostProcessingsMethods\nclass.\n\n\n\nproperty predictions: List[Prediction]\n\nList of all existing Prediction\ninstances in the selection.\n\n\n\nproperty scalars: List[Dict[str, Number]]\n\nList of all existing Scalars\ninstances in the selection."},{"objectID":"API reference","href":"api_reference/selections.html#postprocessing-basics","title":"API reference > Selections > Postprocessing basics","text":"Postprocessing basics\n\nThe post namespace allows you to run and access all postprocessings\nfor existing predictions. For available postprocessings, see the\nSelectionPostProcessingsMethods\nclass.\n\nYou can use the export()\nmethod to export results in batch for exportable postprocessings\n(GlobalCoefficients\nand SurfaceEvolution instances):\n\nNote that a CSV export generates a ZIP file containing multiple CSV files.\nYou can read them directly using Python’s zipfile<https://docs.python.org/3/library/zipfile.html>\nmodule:\n\nYou can download binary postprocessings results by looping on the list:"},{"objectID":"API reference","href":"api_reference/selections.html#postprocessing-api-reference","title":"API reference > Selections > Postprocessing API reference","text":"Postprocessing API reference\n\n\n\n\n\nclass SelectionPostProcessingsMethods\n\nActs as a namespace inside Selection objects,\nallowing you to access or run postprocessings on whole selections.\n\n\n\n\n\nglobal_coefficients() -> ExportablePPList[GlobalCoefficients]\n\nCompute or get the global coefficients of the selected predictions.\n\nThis is a non-blocking method. It returns an\nExportablePPList instance\nof GlobalCoefficients\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on the first call of this method.\nSubsequent calls do not relaunch it.\n\nReturns\n\nExportablePPList instance\nof GlobalCoefficients\nobjects.\n\nReturn type\n\nExportablePPList[GlobalCoefficients]\n\n\n\nslice(axis: str, coordinate: float) -> PPList[Slice]\n\nCompute or get a slice from each prediction in the selection.\n\nThis is a non-blocking method. It returns a\nPPList instance of\nSlice\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on the first call of this method\nwith a specific set of parameters.\nSubsequent calls with the same parameters do not relaunch it.\n\nThe slices are in the NPZ format.\n\nParameters\n\naxis (str) – Axis to slice.\n\ncoordinate (float) – Coordinate along the given axis to slice at.\n\nReturns\n\nPPList list of\nSlice objects.\n\nReturn type\n\nPPList[Slice]\n\n\n\nsurface_evolution(axis: str, delta: float) -> ExportablePPList[SurfaceEvolution]\n\nCompute or get the SurfaceEvolution of the predictions for specific parameters.\n\nThis is a non-blocking method. It returns an\nExportablePPList instance\nof SurfaceEvolution\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on the first call of this method\nwith a specific set of parameters.\nSubsequent calls with the same parameters do not relaunch it.\n\nParameters\n\naxis (str) – Axis to compute the the SurfaceEvolution on.\n\ndelta (float) – Increment of the abscissa in meters.\n\nReturns\n\nExportablePPList instance of\nSurfaceEvolution objects.\n\nReturn type\n\nExportablePPList[SurfaceEvolution]\n\n\n\nsurface_vtp() -> PPList[SurfaceVTP]\n\nCompute or get the surface results of each prediction within the selection, in VTP format.\n\nThis method associates all data with cells; if a variable is originally\nassociated with points in the sample, it would be now associated with cells.\n\nThis is a non-blocking method. It returns a\nPPList instance of\nSurfaceVTP\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nReturns\n\nPPList instance of\nSurfaceVTP objects.\n\nReturn type\n\nPPList[SurfaceVTP]\n\n\n\nsurface_vtp_td_location() -> PPList[SurfaceVTPTDLocation]\n\nCompute or get the surface results of each prediction within the selection, in the VTP format.\n\nThis method keeps the original data association as they are in the sample.\n\nIt is a non-blocking method. It returns a\nPPList instance of\nSurfaceVTPTDLocation,\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nReturns\n\nPPList instance of\nSurfaceVTPTDLocation\n\nReturn type\n\nPPList[SurfaceVTPTDLocation]\n\n\n\nvolume_vtu() -> PPList[VolumeVTU]\n\nCompute or get the result of each prediction’s volume in the VTU format.\n\nThis is a non-blocking method. It returns a\nPPList instance of\nVolumeVTU\nobjects without waiting. Those PostProcessing objects may not have\ndata right away if the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be waited upon with the wait() method.\n\nThe computation is launched only on the first call of this method.\nSubsequent calls do not relaunch it.\n\nReturns\n\nPPList instance of\nVolumeVTU objects.\n\nReturn type\n\nPPList[VolumeVTU]"},{"objectID":"API reference","href":"api_reference/selections.html#collections","title":"API reference > Selections > Collections","text":"Collections\n\n\n\n\n\nclass PPList\n\nProvides a subclass of the list class for storing postprocessings and adding a few shortcut methods.\n\nAs a list subclass, the PPList class supports any list operation.\nIts elements can be iterated on and accessed by index.\n\n\n\n\n\nwait()\n\nWait for all concerned postprocessings to finish.\n\n\n\nproperty data: List[Dict[str, List]] | List[DownloadableResult]\n\nList containing the data of the underlying postprocessings.\n\nThis is a blocking method, which returns once the data of all\npostprocessings is ready.\n\n\n\nclass ExportablePPList\n\nProvides a subclass of the PPList class for downloading the results of a group of postprocessings.\n\nAs a list subclass, the ExportablePPList class supports any list operation.\nIts elements can be iterated on and accessed by index.\n\n\n\n\n\nexport(format: str | None = 'json') -> DownloadableResult\n\nExport the postprocessing results in the desired format.\n\nAccessing this property blocks until the data is ready.\n\nParameters\n\nformat (str | None) – format to exported data in. The default is 'json'.\nOptions are 'csv.zip', 'json', and 'xlsx'.\nNote that the 'csv.zip' option exports a ZIP file containing\nmultiple CSV sheets.\n\nReturns\n\nDownloadableResult object for\ndownloading the exported data into a file or access it in memory.\n\nReturn type\n\nDownloadableResult"},{"objectID":"API reference","href":"api_reference/selections.html#helpers","title":"API reference > Selections > Helpers","text":"Helpers\n\n\n\n\n\nclass DownloadableResult\n\nProvides the object representing a result data for a postprocessing in binary format.\n\n\n\n\n\ndownload(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike) -> None\n\nDownload the postprocessing data to the specified file or path.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike) – Binary file-object or path of the file to download the data into.\n\n\n\nin_memory() -> BytesIO\n\nLoad the postprocessing data in memory.\n\nReturns\n\nio.BytesIO object containing the postprocessing data.\n\nReturn type\n\nBytesIO"},{"objectID":"User guide","href":"user_guide/automorphing/index.html#optimize-geometries","title":"User guide > Optimize geometries","text":"Optimize geometries\n\nIn SimAI, automorphing is a non-parametric deformation of a surface geometry.\n\n"},{"objectID":"User guide","href":"user_guide/configuration_guide/config_file.html#configuration-file","title":"User guide > Configuration file","text":"Configuration file\n\nTo create a SimAIClient\ninstance from a configuration file, you use the\nfrom_config() method:"},{"objectID":"User guide","href":"user_guide/configuration_guide/config_file.html#location","title":"User guide > Configuration file > Location","text":"Location\n\nIf no path is given, the SimAIClient\ninstance looks at default locations. These locations differ according to\nyour operating system.\n\nLinux/MacOS\n\nFor UNIX systems, the default locations are, in order:\n\n$XDG_CONFIG_HOME/ansys_simai.conf\n\n$XDG_CONFIG_HOME/ansys/simai.conf\n\n~/.ansys_simai.conf\n\n~/.ansys/simai.conf\n\n/etc/ansys_simai.conf\n\n/etc/ansys/simai.conf\n\nThe first location found is used. $XDG_CONFIG_HOME defaults to ~/.config.\n\nWindows XP\n\nC:\\Documents and Settings\\<user>\\Local Settings\\Application Data\\Ansys\\simai.conf\n\nWindows 7 to 11\n\nC:\\Users\\<user>\\AppData\\Roaming\\Ansys\\simai.conf\n\nOptionally, you can specify the path yourself:"},{"objectID":"User guide","href":"user_guide/configuration_guide/config_file.html#content","title":"User guide > Configuration file > Content","text":"Content\n\nYou write the configuration file in TOML.\nFrom this file, you can pass parameters for configuring\nthe SimAIClient instance (see configuration)."},{"objectID":"User guide","href":"user_guide/configuration_guide/config_file.html#example","title":"User guide > Configuration file > Example","text":"Example"},{"objectID":"User guide","href":"user_guide/configuration_guide/config_file.html#profiles","title":"User guide > Configuration file > Profiles","text":"Profiles\n\nThe SimAIClient instance supports having multiple\nconfigurations in a single file through profiles, which are loaded like this:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#interpolating-between-geometries","title":"Interpolating Between Geometries","text":"Interpolating Between Geometries\n\nThis example demonstrates how to interpolate between two geometries in latent space.\n\nLatent space interpolation allows you to:\n\nCreate smooth transitions between existing designs.\n\nExplore the design space systematically.\n\nGenerate variations that blend features from multiple geometries."},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#before-you-begin","title":"Interpolating Between Geometries > Before you begin","text":"Before you begin\n\nComplete “ref_build_model” to train a Generative design model.\n\nEnsure that the model training has been completed successfully. To do so, verify if a new workspace was created for the trained model."},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#import-necessary-libraries","title":"Interpolating Between Geometries > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#configure-your-settings","title":"Interpolating Between Geometries > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#define-the-interpolation-function","title":"Interpolating Between Geometries > Define the interpolation function","text":"Define the interpolation function\n\nBefore running predictions, we need a function to interpolate between two latent vectors."},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#initialize-the-client-and-get-the-workspace","title":"Interpolating Between Geometries > Initialize the client and get the workspace","text":"Initialize the client and get the workspace\n\nConnect to GeomAI and retrieve your trained workspace:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#get-latent-parameters-for-all-geometries","title":"Interpolating Between Geometries > Get latent parameters for all geometries","text":"Get latent parameters for all geometries\n\nDownload the latent parameters of all training geometries in the workspace:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#display-available-geometries","title":"Interpolating Between Geometries > Display available geometries","text":"Display available geometries\n\nList all geometries available for interpolation:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#validate-selected-geometries","title":"Interpolating Between Geometries > Validate selected geometries","text":"Validate selected geometries\n\nCheck if the selected geometries exist:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#interpolate-in-latent-space-and-generate-geometries","title":"Interpolating Between Geometries > Interpolate in latent space and generate geometries","text":"Interpolate in latent space and generate geometries\n\nGenerate intermediate geometries by linearly interpolating in latent space:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#download-generated-geometries","title":"Interpolating Between Geometries > Download generated geometries","text":"Download generated geometries\n\nThe downloaded VTP files can be used for:\n\nVisualization in your usual solver.\n\nSimAI training data or predictions.\n\nFurther analysis and post-processing."},{"objectID":"Home","href":"_examples/02_generative_design_ex/03-interpolate_geometries.html#next-steps","title":"Interpolating Between Geometries > Next steps","text":"Next steps\n\nTo go further, you can:\n\nInterpolate between more than two geometries.\n\nCombine interpolation with optimization for specific design goals.\n\n\n\nDownload Jupyter notebook: 03-interpolate_geometries.ipynb\n\nDownload Python source code: 03-interpolate_geometries.py\n\nDownload zipped: 03-interpolate_geometries.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"Home","href":"_examples/index.html#examples","title":"Examples","text":"Examples"},{"objectID":"Home","href":"_examples/index.html#simai-basics","title":"Examples > SimAI basics","text":"SimAI basics\n\nThis section provides a collection of practical script examples illustrating the basic SimAI workflow.\nThey serve as a step-by-step guide for users to get started with SimAI.\n\nsphx_glr__examples_00_basic_simai_ex_00-create_project_upload_data.py\n\nsphx_glr__examples_00_basic_simai_ex_01-build_model.py\n\nsphx_glr__examples_00_basic_simai_ex_02-run_predictions.py"},{"objectID":"Home","href":"_examples/index.html#pysimai-utilities","title":"Examples > PySimAI utilities","text":"PySimAI utilities\n\nThis section provides a collection of practical script examples illustrating SimAI functionalities and use cases.\nThey serve as a reference guide for users to implement similar solutions in their projects.\n\nsphx_glr__examples_01_pysimai_ex_00-model_configuration_reuse.py\n\nsphx_glr__examples_01_pysimai_ex_01-model_recomputation.py\n\nsphx_glr__examples_01_pysimai_ex_02-subset_assignment.py\n\nsphx_glr__examples_01_pysimai_ex_03-list_based_subset_assignment.py"},{"objectID":"Home","href":"_examples/index.html#generative-design","title":"Examples > Generative Design","text":"Generative Design\n\nThis section provides a collection of practical script examples illustrating the Generative Design feature of SimAI.\nThey serve as a reference guide for users to implement similar solutions in their projects.\n\nsphx_glr__examples_02_generative_design_ex_00-create_project_upload_data.py\n\nsphx_glr__examples_02_generative_design_ex_01-build_model.py\n\nsphx_glr__examples_02_generative_design_ex_02-generate_random_geometries.py\n\nsphx_glr__examples_02_generative_design_ex_03-interpolate_geometries.py\n\n\n\nGallery generated by Sphinx-Gallery"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#creating-a-simai-project-and-uploading-training-data","title":"Creating a SimAI Project and Uploading Training Data","text":"Creating a SimAI Project and Uploading Training Data\n\nThis example demonstrates how to connect to SimAI, create a new project, and upload training data folders."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#before-you-begin","title":"Creating a SimAI Project and Uploading Training Data > Before you begin","text":"Before you begin\n\nMake sure you have:\n\nValid SimAI credentials and organization access.\n\nA dataset folder containing subdirectories with your training data.\n\nThe ansys-simai-core library installed."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#import-necessary-libraries","title":"Creating a SimAI Project and Uploading Training Data > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#configure-your-settings","title":"Creating a SimAI Project and Uploading Training Data > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#initialize-the-simai-client","title":"Creating a SimAI Project and Uploading Training Data > Initialize the SimAI client","text":"Initialize the SimAI client\n\nCreate a client to connect to the SimAI platform:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#set-up-the-project","title":"Creating a SimAI Project and Uploading Training Data > Set up the project","text":"Set up the project\n\nTry to get an existing project by name, or create it if it does not exist:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#set-as-the-current-working-project","title":"Creating a SimAI Project and Uploading Training Data > Set as the current working project","text":"Set as the current working project\n\nSetting the current project allows subsequent operations to use this project by default:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#upload-training-data","title":"Creating a SimAI Project and Uploading Training Data > Upload training data","text":"Upload training data\n\nUpload all directories from the dataset path as training data.\nEach subdirectory should contain the files for one training data sample."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#check-and-wait-for-data-processing","title":"Creating a SimAI Project and Uploading Training Data > Check and wait for data processing","text":"Check and wait for data processing\n\nAfter uploading, SimAI needs to process the training data.\nGet all data in the current project and wait for them to be ready."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#display-project-status-summary","title":"Creating a SimAI Project and Uploading Training Data > Display project status summary","text":"Display project status summary\n\nShow a summary of the project’s data processing status:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/00-create_project_upload_data.html#next-steps","title":"Creating a SimAI Project and Uploading Training Data > Next steps","text":"Next steps\n\nOnce all data are ready, you can proceed to configure and build a model.\nSee the next tutorial: ref_basic_build_model\n\n\n\nDownload Jupyter notebook: 00-create_project_upload_data.ipynb\n\nDownload Python source code: 00-create_project_upload_data.py\n\nDownload zipped: 00-create_project_upload_data.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"User guide","href":"user_guide/pysimai_ug/data_exploration.html#data-exploration","title":"User guide > Data exploration","text":"Data exploration\n\nThe SimAI client provides utilities to help you run a large number of predictions and\npostprocessings, explore your data, and gather insights from it."},{"objectID":"User guide","href":"user_guide/pysimai_ug/data_exploration.html#selections","title":"User guide > Data exploration > Selections","text":"Selections\n\nselections enable you to manipulate a large number of geometries and scalars\nsimultaneously. They also allow you to easily run many predictions or postprocessings in parallel.\n\nYou create a selection by combining a list of geometries with a list of scalars:\n\nTo help build selections, the Sim AI client exposes two methods that are useful for\ndifferent strategies:\n\nThe geometry.sweep method, which\nis described in sweeping.\n\nThe GeometryDirectory.list\nmethod, which is described in filtering_geometries.\n\nFor more information on selections and geometry exploration methods, see selections\nand geometries.\n\n"},{"objectID":"User guide","href":"user_guide/pysimai_ug/data_exploration.html#sweeping","title":"User guide > Data exploration > Sweeping","text":"Sweeping\n\nThe geometry.sweep method allows you\nto explore the surroundings of a given geometry, which can help with local optimization or\ngradient descent. This method, only for numerical metadata, finds geometries that have\nmetadata closest to the candidate geometry.\n\n"},{"objectID":"User guide","href":"user_guide/pysimai_ug/data_exploration.html#filtering-geometries","title":"User guide > Data exploration > Filtering geometries","text":"Filtering geometries\n\nThe GeometryDirectory.list method\nallows you to take a more brute-force approach. With this method, you can select large swaths of\ngeometries with range filters."},{"objectID":"API reference","href":"api_reference.html#api-reference","title":"API reference","text":"API reference\n\n"},{"objectID":"API reference","href":"api_reference.html#geomai-api-reference","title":"API reference > GeomAI API reference","text":"GeomAI API reference\n\n"},{"objectID":"API reference","href":"api_reference/training_data_parts.html#trainingdataparts","title":"API reference > TrainingDataParts","text":"TrainingDataParts\n\n\n\nA TrainingDataPart instance\nis a singular file that is part of a TrainingData\ninstance."},{"objectID":"API reference","href":"api_reference/training_data_parts.html#directory","title":"API reference > TrainingDataParts > Directory","text":"Directory\n\n\n\nclass TrainingDataPartDirectory(client: ansys.simai.core.client.SimAIClient)\n\nProvides the collection of methods related to training data parts.\n\nThis class is accessed through client.training_data_parts.\n\n\n\n\n\nget(id: str) -> TrainingDataPart\n\nGet a TrainingDataPart object from the server.\n\n"},{"objectID":"API reference","href":"api_reference/training_data_parts.html#model","title":"API reference > TrainingDataParts > Model","text":"Model\n\n\n\nclass TrainingDataPart(*args, **kwargs)\n\nProvides the local representation of a training data part object.\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty name: str\n\nName of the file.\n\n\n\nproperty size: int\n\nSize of the file in bytes."},{"objectID":"API reference","href":"api_reference/geomai/client.html#geomaiclient","title":"API reference > GeomAIClient","text":"GeomAIClient\n\n\n\n\n\nclass GeomAIClient\n\n\n\n\n\nset_current_project(name: str)\n\nSet the current project for the GeomAI client.\n\nThis method affects how some methods related to projects or associated\ndata behave.\n\nParameters\n\nname (str) – Name of the project that the client should switch to.\n\n\n\nset_current_workspace(name: str)\n\nSet the current workspace for the GeomAI client.\n\nParameters\n\nname (str) – Name of the workspace that the client should switch to.\n\n\n\nproperty current_project: GeomAIProject\n\nProject currently used by the GeomAI client.\n\nYou should not set the project directly. Instead, use the set_current_project()\nmethod, which uses the project name and ensures that the project exists.\n\n\n\nproperty current_workspace: GeomAIWorkspace\n\nWorkspace currently used by the GeomAI client.\n\nYou should not set the workspace directly. Instead, use the set_current_workspace()\nmethod, which uses the workspace name and ensures that the workspace exists.\n\n\n\nproperty models: GeomAIModelDirectory\n\nRepresentation of all GeomAI models on the server.\nFor more information, see geomai_models.\n\n\n\nproperty predictions: GeomAIPredictionDirectory\n\nRepresentation of all GeomAI predictions on the server.\nFor more information, see geomai_predictions.\n\n\n\nproperty projects: GeomAIProjectDirectory\n\nRepresentation of all GeomAI projects on the server.\nFor more information, see geomai_projects.\n\n\n\nproperty training_data: GeomAITrainingDataDirectory\n\nRepresentation of all GeomAI training data on the server.\nFor more information, see geomai_training_data.\n\n\n\nproperty training_data_parts: GeomAITrainingDataPartDirectory\n\nRepresentation of all GeomAI training data parts on the server.\nFor more information, see geomai_training_data_parts.\n\n\n\nproperty workspaces: GeomAIWorkspaceDirectory\n\nRepresentation of all GeomAI workspaces on the server.\nFor more information, see geomai_workspaces."},{"objectID":"User guide","href":"user_guide/generative_design_ug/generative_design.html#generative-design","title":"User guide > Generative design","text":"Generative design\n\nLearn about the parameters to set to generate a new design based on a trained model."},{"objectID":"User guide","href":"user_guide/generative_design_ug/generative_design.html#latent-parameters","title":"User guide > Generative design > Latent parameters","text":"Latent parameters\n\nThe latent parameters (latent_params) correspond to a list of numbers (floats) that represent the position of the geometry in the latent space.\nYou define this parameter to generate a geometry with a trained model.\n\nThe number of floats must match the nb_latent_param your model was requested with.\nFor more information, see Number of latent parameters."},{"objectID":"User guide","href":"user_guide/generative_design_ug/generative_design.html#resolution","title":"User guide > Generative design > Resolution","text":"Resolution\n\nThe resolution parameter is a list of three integers defining the number of voxels along the X, Y, and Z axes.\n\nUse higher resolution for complex or precise geometries, and lower resolution for simple shapes or quick previews.\n\nThe total number of voxels must not exceed 900^3, that is x, y, z multiplied together must be less than or equal to 900^3.\nIf you exceed that value, an error occurs.\n\nDefaults to [100,100,100], if None is provided.\n\nFor the maximum resolution of 900^3, the prediction takes approximately 10 minutes (approximately 1 microsecond per voxel)."},{"objectID":"API reference","href":"api_reference/data_types.html#data-types","title":"API reference > Data types","text":"Data types\n\n\n\n\n\nclass Range(min: float | None = None, max: float | None = None, tolerance: float | None = None)\n\nDescribes a numerical range used for filtering geometries.\n\nRange objects describe a numerical range between a minimum and\na maximum boundary. Both are optional. Thus, if no maximum boundary\nis passed, the range describes values greater than or equal to the\nminimum boundary. Note that ranges are inclusive. Thus, both minimum\nand maximum boundaries match if they are equal to the passed value\n(as opposed to Python’s range() method).\n\nRanges can be used as a filter in the\ngeometries.list method.\n\nParameters\n\nmin (float | None) – Minimum boundary.\n\nmax (float | None) – Maximum boundary.\n\ntolerance (float | None) – Tolerance delta. Two values whose difference is smaller\nthan the tolerance are considered as equal.\n\n\n\nmatch_value(value: float) -> bool\n\nDetermine whether the given value belongs to the Range class.\n\n\n\n\n\nclass RawSingleFilter\n\n\n\n\n\nclass SizedIterator(*args, **kwargs)\n\nAlias of Iterator[T] & Sized.\n\n\n\nclass SubsetEnum(*values)\n\nSubsetEnum: enumeration of possible subsets TrainingData can belong to if any.\n\n\n\nunpack_named_file(named_file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) -> Generator[Tuple[BinaryIO, str, str], None, None]\n\nUnpack a named file by providing a readable file, its name, and an extension.\n\n\n\n\n\nBoundaryConditions\n\nBoundaryConditions describes the external conditions of a prediction.\n\nalias of Dict[str, Number]\n\n\n\nFile\n\nEither a binary file-object (typing.BinaryIO) or a Path.\n\nalias of BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike\n\n\n\nFilters\n\nFilters type for list() endpoints that support them.\n\nThe simplified Filters syntax (only for EQ filters) is: {\"name\": \"my-experiment\"}.\nThe full syntax is: [(\"name\", \"LIKE\", \"%thingy%\"), (\"size\", \"GT\", 9000)].\nIn both cases, the conditions are AND together.\n\nalias of dict[str, Any] | list[tuple[str, Literal[‘EQ’, ‘LIKE’, ‘IN’, ‘GT’, ‘GTE’, ‘LT’, ‘LTE’], Any]] | list[RawSingleFilter]\n\n\n\nIdentifiable\n\nEither a model or the string ID of an object of the same type.\n\nalias of DataModelType | str\n\n\n\nMonitorCallback\n\nCallback used to monitor the download or upload of a file.\n\nFor downloads, the callback is called one time with the total size of the download.\nSubsequent calls are passed the number of bytes read in this iteration.\n\nFor uploads, the callback receives the number of bytes written each iteration.\n\nalias of Callable[[int], None]\n\n\n\nNamedFile\n\nA named file is either a FilePath, from which a name can be inferred, or a tuple with a file and a name.\nTo be valid, the name needs to contain an extension.\n\nExample\n\nalias of Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]\n\n\n\nPath\n\nPath to a file or folder as an pathlib.Path object or a format supported by pathlib.\n\nalias of Path | str | PathLike\n\n\n\nScalars\n\nScalars describes the external conditions of a prediction.\n\nalias of Dict[str, Number]"},{"objectID":"User guide","href":"user_guide/configuration_guide/index.html#configure-your-instance","title":"User guide > Configure your instance","text":"Configure your instance\n\n"},{"objectID":"User guide","href":"user_guide/pysimai_ug/best_practices.html#best-practices","title":"User guide > Best practices","text":"Best practices"},{"objectID":"User guide","href":"user_guide/pysimai_ug/best_practices.html#asynchronicity","title":"User guide > Best practices > Asynchronicity","text":"Asynchronicity\n\nWhile the SimAI client doesn’t use async/await mechanics, it is somewhat asynchronous in nature.\nWhile uploading geometries is a blocking method, running a prediction or a postprocessing returns\nthe created object immediately, before the result is computed on the servers or available locally.\nThis behavior makes it possible to request that multiple computations be run on the SimAI platform\nwithout waiting for any of the data to be available.\n\nTo wait for an object to be fully available, you can call the wait() method on the object.\nFor example, you can call the Prediction.wait()\nmethod on a prediction. Or, you can call the global SimAIClient.wait()\nmethod to wait for all requests to complete.\n\nAlternatively, you can try to access the object’s data, in which case the SimAI client automatically\nwaits for the data to be ready if needed. Because of this behavior, when running a large number of\ncomputations, you should send all requests before accessing any of the data.\n\nThis example requests the predictions and postprocessings sequentially, which requires waiting\nfor the data to be available and used before requesting the next one.\n\nThis more efficient example requests all the predictions and postprocessings right away\nand then processes the data once they are all available."},{"objectID":"API reference","href":"api_reference/geomai/workspaces.html#geomaiworkspaces","title":"API reference > GeomAIWorkspaces","text":"GeomAIWorkspaces\n\n\n\nWorkspaces are a set of specific predictions.\nEach workspace uses a specific model.\n\nYou use the GeomAIClient.set_current_workspace()\nmethod to set the workspace that the client is configured for."},{"objectID":"API reference","href":"api_reference/geomai/workspaces.html#directory","title":"API reference > GeomAIWorkspaces > Directory","text":"Directory\n\n\n\nclass GeomAIWorkspaceDirectory\n\nProvides a collection of methods related to GeomAI workspaces.\n\nThis class is accessed through client.geomai.workspaces.\n\nExample\n\n\n\n\n\ncreate(name: str, project: GeomAIProject | str) -> GeomAIWorkspace\n\nCreate a workspace.\n\nParameters\n\nname (str) – Name to give the new workspace.\n\nproject (GeomAIProject | str) – ID or project of the workspace.\n\n\n\ndelete(workspace: GeomAIWorkspace | str) -> None\n\nDelete a workspace.\n\nParameters\n\nworkspace (GeomAIWorkspace | str) – ID or model of the workspace.\n\n\n\nget(id: str | None = None, name: str | None = None) -> GeomAIWorkspace\n\nGet a specific workspace object from the server by either ID or name.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the workspace.\n\nname (str | None) – Name of the workspace.\n\nReturns\n\nA GeomAIWorkspace.\n\nRaises\n\nNotFoundError – No workspace with the given ID exists.\n\nReturn type\n\nGeomAIWorkspace\n\n\n\nlist() -> List[GeomAIWorkspace]\n\nList all workspaces from the server.\n\n"},{"objectID":"API reference","href":"api_reference/geomai/workspaces.html#model","title":"API reference > GeomAIWorkspaces > Model","text":"Model\n\n\n\nclass GeomAIWorkspace\n\nProvides the local representation of a GeomAI workspace object.\n\n\n\ndelete()\n\nDelete the workspace.\n\n\n\ndownload_latent_parameters_json(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the json file containing the latent parameters for the model’s training data.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\ndownload_model_evaluation_report(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the ZIP file of the model evaluation report for the workspace.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\nget_latent_parameters() -> dict[str, List[float]]\n\nGet the dictionary mapping geometry names to their latent parameter vectors for the model’s training data.\n\n\n\n\n\nlist_predictions() -> List[GeomAIPrediction]\n\nLists all the predictions in the workspace.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nrename(new_name: str) -> None\n\nRename the workspace.\n\nParameters\n\nnew_name (str) – New name to give to the workspace.\n\n\n\nset_as_current_workspace() -> None\n\nConfigure the client to use this workspace instead of the one currently configured.\n\n\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty model_configuration: GeomAIModelConfiguration\n\nModel configuration used in the workspace.\n\n\n\nproperty name: str\n\nName of the workspace."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#creating-a-geomai-project-and-uploading-training-data","title":"Creating a GeomAI Project and Uploading Training Data","text":"Creating a GeomAI Project and Uploading Training Data\n\nThis example demonstrates how to connect to the instance, create a new project, and upload geometry files as training data."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#before-you-begin","title":"Creating a GeomAI Project and Uploading Training Data > Before you begin","text":"Before you begin\n\nMake sure you have:\n\nValid SimAI credentials and organization access.\n\nA folder containing geometry files (.vtp or .stl format).\n\nThe ansys-simai-core library installed."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#import-necessary-libraries","title":"Creating a GeomAI Project and Uploading Training Data > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#configure-your-settings","title":"Creating a GeomAI Project and Uploading Training Data > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#create-the-client","title":"Creating a GeomAI Project and Uploading Training Data > Create the client","text":"Create the client\n\nCreate a client to use the PySimAI library. This client will be the\nentrypoint for all Generative Design objects."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#create-or-retrieve-a-project","title":"Creating a GeomAI Project and Uploading Training Data > Create or retrieve a project","text":"Create or retrieve a project\n\nTry to get an existing project by name, or create it if it does not exist:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#upload-training-data-to-the-project","title":"Creating a GeomAI Project and Uploading Training Data > Upload training data to the project","text":"Upload training data to the project\n\nLoop through all geometry files in your dataset folder and upload them.\nThe script handles duplicates by checking if the data already exist."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#check-and-wait-for-data-processing","title":"Creating a GeomAI Project and Uploading Training Data > Check and wait for data processing","text":"Check and wait for data processing\n\nAfter uploading, the instance needs to process the geometries. This script\ndisplays the progress of the data processing."},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#display-project-status-summary","title":"Creating a GeomAI Project and Uploading Training Data > Display project status summary","text":"Display project status summary\n\nShow a summary of the project’s data processing status:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/00-create_project_upload_data.html#next-steps","title":"Creating a GeomAI Project and Uploading Training Data > Next steps","text":"Next steps\n\nOnce all data is ready, you can proceed to build a model.\nSee the next example: ref_build_model.\n\n\n\nDownload Jupyter notebook: 00-create_project_upload_data.ipynb\n\nDownload Python source code: 00-create_project_upload_data.py\n\nDownload zipped: 00-create_project_upload_data.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"API reference","href":"api_reference/current_user.html#current-user","title":"API reference > Current user","text":"Current user\n\n\n\nThe current user module provides self-management operations for the authenticated user,\nincluding offline token generation and consent management.\n\nYou access the current user through the SimAIClient.me\nproperty."},{"objectID":"API reference","href":"api_reference/current_user.html#example","title":"API reference > Current user > Example","text":"Example"},{"objectID":"API reference","href":"api_reference/current_user.html#currentuser","title":"API reference > Current user > CurrentUser","text":"CurrentUser\n\n\n\nclass CurrentUser\n\nProvides access to current user self-management operations.\n\nThis class allows users to manage their own account settings, generate\noffline tokens, and manage consents.\n\nExample\n\n\n\n\n\ngenerate_offline_token() -> str\n\nGenerate a new offline token for the current user.\n\nThis creates a long-lived refresh token that can be used for authentication\nwithout requiring interactive login. The token is associated with the “sdk”\nclient ID.\n\nReturns\n\nThe offline token string that can be stored and used for future authentication.\n\nReturn type\n\nstr\n\nExample\n\n\n\nproperty consents: ConsentDirectory\n\nAccess consent management operations.\n\nReturns\n\nConsentDirectory for managing offline access consents."},{"objectID":"API reference","href":"api_reference/current_user.html#consentdirectory","title":"API reference > Current user > ConsentDirectory","text":"ConsentDirectory\n\n\n\nclass ConsentDirectory\n\nProvides access to consent management operations.\n\nConsents represent the authorization records that grant a client (like the SDK)\npermission to use offline tokens for authentication.\n\nExample\n\n\n\n\n\nlist() -> List[Consent]\n\nList all offline access consents for the current user.\n\nReturns\n\nList of Consent objects representing the user’s offline access consents.\n\nReturn type\n\nList[Consent]\n\nExample\n\n\n\nrevoke(client_id: str) -> None\n\nRevoke an offline access consent for the current user.\n\nThis will invalidate the consent associated with the given client ID,\npreventing any further use of offline tokens for that client.\n\nParameters\n\nclient_id (str) – The client ID of the consent to revoke.\n\nRaises\n\nNotFoundError – If no consent exists for the given client ID.\n\nExample\n\nRevoking a consent will invalidate any offline tokens associated with\nthat client. Server-side workflows using those tokens will stop working."},{"objectID":"API reference","href":"api_reference/current_user.html#consent","title":"API reference > Current user > Consent","text":"Consent\n\n\n\nclass Consent\n\nRepresents a consent granted by the current user to a client (like the SDK).\n\n\n\n\n\nclient_id: str\n\nThe client ID that has been granted offline access.\n\n\n\ncreated_date: datetime\n\nWhen the consent was originally granted.\n\n\n\ngranted_scopes: List[str]\n\nList of scopes granted to this client.\n\n\n\nlast_updated_date: datetime\n\nWhen the consent was last updated."},{"objectID":"API reference","href":"api_reference/predictions.html#predictions","title":"API reference > Predictions","text":"Predictions\n\n\n\n\n\nThe Prediction module is in charge of running the SimAI-powered\npredictions on the geometries\nthat you have uploaded.\n\nA prediction represents a numerical prediction with geometry and scalars.\nThe arguments to the predictions.run() method\ndepend on your model."},{"objectID":"API reference","href":"api_reference/predictions.html#directory","title":"API reference > Predictions > Directory","text":"Directory\n\n\n\nclass PredictionDirectory\n\nProvides a collection of methods related to model predictions.\n\nThis method is accessed through client.prediction.\n\nExample\n\n\n\n\n\ndelete(prediction: Prediction | str) -> None\n\nDelete a specific prediction from the server.\n\nParameters\n\nprediction (Prediction | str) – ID or model of the prediction.\n\nRaises\n\nansys.simai.core.errors.NotFoundError – No prediction with the given ID exists.\n\n\n\nget(id: str) -> Prediction\n\nGet a specific prediction object from the server by ID.\n\nParameters\n\nid (str) – ID of the prediction.\n\nReturns\n\nPrediction instance with the given ID if it exists.\n\nRaises\n\nNotFoundError – No prediction with the given ID exists.\n\nReturn type\n\nPrediction\n\n\n\nlist(workspace: Workspace | str | None = None) -> List[Prediction]\n\nList all predictions on the server that belong to the specified workspace or the configured one.\n\nParameters\n\nworkspace (Workspace | str | None) – ID or model of the workspace to list the predictions for.\nThis parameter is necessary if no workspace is set for the client.\n\n\n\nrun(geometry: Geometry | str, scalars: Dict[str, Number] | None = None, boundary_conditions: Dict[str, Number] | None = None, **kwargs) -> Prediction\n\nRun a prediction on a given geometry with a given scalars.\n\nScalars can be passed as a dictionary or as kwargs.\n\nTo learn more about the expected scalars in your workspace, you can use the\nsimai.current_workspace.model_manifest.scalars or simai.predictions.scalars\nmethod, where ex is your ~ansys.simai.core.client.SimAIClient object.\n\nParameters\n\ngeometry (Geometry | str) – ID or model of the target geometry.\n\nscalars (Dict[str, Number] | None) – Scalars to apply in dictionary form.\n\nboundary_conditions (Dict[str, Number] | None) – (Deprecated) Boundary conditions to apply in dictionary form.\n\nReturns\n\nCreated prediction object.\n\nRaises\n\nProcessingError – If the server failed to process the request.\n\nReturn type\n\nPrediction\n\nExamples\n\nUsing kwargs:\n\n\n\nproperty boundary_conditions: Dict[str, Any]\n\n(Deprecated) Information on the boundary conditions expected by the model of the current workspace.\nFor example, the prediction’s input.\n\n\n\nproperty info\n\nInformation on the prediction’s inputs and outputs.\n\nExample\n\n\n\nproperty physical_quantities: Dict[str, Any]\n\nInformation on the physical quantities generated by the model. For example, the\nprediction’s output.\n\n\n\nproperty scalars: Dict[str, Any]\n\nInformation on the scalars expected by the model of the current workspace.\nFor example, the prediction’s input."},{"objectID":"API reference","href":"api_reference/predictions.html#model","title":"API reference > Predictions > Model","text":"Model\n\n\n\nclass Prediction\n\nProvides the local representation of a prediction object.\n\n\n\ndelete() -> None\n\nRemove a prediction from the server.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty boundary_conditions: Dict[str, Number]\n\n(Deprecated) Boundary conditions of the prediction.\n\n\n\nproperty confidence_score: str | None\n\nConfidence score, which is either high or low.\n\nThis method blocks until the confidence score is computed.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty geometry: Geometry\n\nParent geometry.\n\nThe parent geometry is queried if is not already known by the current\nSimAI client session.\n\ngeometry_id: Get the parent geometry’s ID without query.\n\n\n\nproperty geometry_id: str\n\nID of the parent geometry.\n\ngeometry: Get the parent geometry.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty post: PredictionPostProcessings\n\nNamespace containing methods for postprocessing the result of a prediction.\n\nFor more information, see the PredictionPostProcessings\nclass.\n\n\n\nproperty raw_confidence_score: float | None\n\nRaw confidence score, a float.\n\nThis method blocks until the confidence score is computed.\n\n\n\nproperty scalars: Dict[str, Number]\n\nScalars of the prediction."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#non-parametric-optimization","title":"User guide > Non-parametric optimization","text":"Non-parametric optimization\n\nSimAI’s non-parametric optimization feature is a process used to improve the performance of a given geometry\n(referred to as the baseline geometry) by applying smooth, data-driven deformations based on predicted sensitivity maps.\n\nThis approach is especially relevant when there are no predefined building parameters, and it would be too difficult to\ndefine them retroactively.\nIn such cases, non-parametric optimization must be performed, as it enables you to optimize the provided shape directly\nby applying smooth and continuous deformations to the baseline geometry.\nThis helps you explore the design space and make shape changes based on an objective function\nwithout generating new geometries themselves or reparametrizing existing designs.\n\nThis is where automorphing comes in:\nSimAI uses this approach to automatically generate new geometries through goal-driven shape deformations\ndirectly applied to non-parameterized baseline geometries.\n\nUnlike traditional parametric methods, this approach requires no predefined design variables and\nenables you to optimize existing geometries seamlessly, directly within the SimAI platform.\n\nPlease note that the feature is currently available via SDK only through the method run_non_parametric.\nFor more information, see Optimization."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#how-to-perform-non-parametric-optimization","title":"User guide > Non-parametric optimization > How to perform non-parametric optimization","text":"How to perform non-parametric optimization\n\nRequirements for the training data:\n\nRobust data preparation is the first step to successfully running the non-parametric optimization.\nMake sure the maximum magnitude within the simulation data is around the minimal optimization gain you want.\nFor example, for a reduction of at least 4% on the drag, make sure there is around 4% drag difference\nbetween the best and the worst from the simulation data."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#workflow-to-perform-an-effective-non-parametric-optimization","title":"User guide > Non-parametric optimization > Workflow to perform an effective non-parametric optimization","text":"Workflow to perform an effective non-parametric optimization"},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#step-1-data-upload-to-simai","title":"User guide > Non-parametric optimization > Step 1. Data upload to SimAI","text":"Step 1. Data upload to SimAI\n\nSelect the surface geometries that you want to optimize based on the requirements above.\n\nPrepare the geometry files to be compliant with SimAI.\n\nFor more information, see the online SimAI User’s Guide.\n\nUpload those geometry files to SimAI.\n\n"},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#step-2-train-simai-model","title":"User guide > Non-parametric optimization > Step 2. Train SimAI model","text":"Step 2. Train SimAI model\n\nCreate a project in SimAI and assign the geometries to it.\n\nBuild an AI model, trained with those geometries.\n\nWhen the AI model is finished, it creates a workspace for that model training and automatically chooses a reference sample."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#step-3-optimization","title":"User guide > Non-parametric optimization > Step 3. Optimization","text":"Step 3. Optimization\n\nPerform a non-parametric optimization by calling the run_non_parametric function.\n\nAt each optimization loop, automorphed geometries are uploaded to the workspace.\n\nThe number of automorphed geometries uploaded to the workspace depends on the n_iters configured.\n\nRun predictions, postprocessings, etc. on the generated geometries, if needed."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#step-4-solver-verification","title":"User guide > Non-parametric optimization > Step 4. Solver verification","text":"Step 4. Solver verification\n\nDownload randomly selected geometries produced from the various iteration stages throughout the optimization process.\n\nRun a simulation in your solver to select the optimum among the downloaded geometries."},{"objectID":"User guide","href":"user_guide/automorphing/non-parametric_optimization.html#step-5-enrich-training-data","title":"User guide > Non-parametric optimization > Step 5. Enrich training data","text":"Step 5. Enrich training data\n\nAdd the chosen optimums as new training data to your model.\n\nBuild a new AI model with those new data.\n\nUse again the SDK non-parametric optimization feature by calling the run_non_parametric function.\n\nRepeat the workflow from Step 3 at least three times. It is usually the number needed to achieve good results.\n\nStop running optimization whenever the performance result obtained on Step 4 is satisfactory.\nThe idea is to make the model learn from its previous prediction."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#building-a-simai-model","title":"Building a SimAI Model","text":"Building a SimAI Model\n\nThis example demonstrates how to configure a SimAI model with inputs, outputs, global coefficients,\nand domain of analysis, then start the model training process."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#before-you-begin","title":"Building a SimAI Model > Before you begin","text":"Before you begin\n\nComplete “ref_basic_create_project_upload_data” to create a project with training data.\n\nEnsure all training data in your project are ready (processed successfully).\n\nKnow the names of surfaces and boundary conditions in your training data.\n\nDetermine which global coefficients you want to calculate."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#import-necessary-libraries","title":"Building a SimAI Model > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#configure-your-settings","title":"Building a SimAI Model > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#initialize-the-client-and-get-the-project","title":"Building a SimAI Model > Initialize the client and get the project","text":"Initialize the client and get the project\n\nConnect to SimAI:\n\nRetrieve the project by name:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#configure-model-inputs","title":"Building a SimAI Model > Configure model inputs","text":"Configure model inputs\n\nDefine which surfaces and boundary conditions the model will use as inputs.\nReplace the placeholder names with the actual names from your training data:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#configure-model-outputs","title":"Building a SimAI Model > Configure model outputs","text":"Configure model outputs\n\nDefine which surfaces the model will predict.\nThese are typically the same surfaces as the inputs, but you can specify different ones:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#define-global-coefficients","title":"Building a SimAI Model > Define global coefficients","text":"Define global coefficients\n\nGlobal coefficients are scalar values calculated from the prediction results.\nThey can be used to extract key performance indicators from your simulations.\n\nIn this example, we calculate the integral of a field called “Photometric”.\nYou can define multiple global coefficients with different formulas.\n\nAvailable locations: \"points\" or \"cells\"."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#define-domain-of-analysis","title":"Building a SimAI Model > Define domain of analysis","text":"Define domain of analysis\n\nThe domain of analysis specifies the spatial extent that the model will analyze.\nValues can be specified as absolute dimensions or relative to minimum values.\n\nFormat: reference_type, min_value, max_value\n\nreference_type: \"relative_to_min\", \"relative_to_max\", \"relative_to_center” or \"absolute\".\n\nmin_value: minimum dimension value.\n\nmax_value: maximum dimension value.\n\nYou can find appropriate values by analyzing your training data in the SimAI platform."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#create-model-configuration","title":"Building a SimAI Model > Create model configuration","text":"Create model configuration\n\nCombine all the configuration elements into a ModelConfiguration object.\n\nBuild presets determine the training duration:\n\ndebug: Quick training for testing.\n\n1_day: Short training.\n\n2_days: Standard training (recommended).\n\n7_days: Maximum training for best accuracy."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#verify-and-build-the-model","title":"Building a SimAI Model > Verify and build the model","text":"Verify and build the model\n\nBefore building, check if the project meets all requirements for training:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/01-build_model.html#next-steps","title":"Building a SimAI Model > Next steps","text":"Next steps\n\nOnce your model is trained, you can:\n\nMonitor the training progress in the SimAI platform.\n\nRun predictions on new geometries: ref_basic_run_predictions.\n\nEvaluate model performance using validation data.\n\n\n\nDownload Jupyter notebook: 01-build_model.ipynb\n\nDownload Python source code: 01-build_model.py\n\nDownload zipped: 01-build_model.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"User guide","href":"user_guide/generative_design_ug/index.html#generate-new-designs","title":"User guide > Generate new designs","text":"Generate new designs\n\nWith SimAI, you generate new geometries based on existing ones.\n\nThe steps to follow are:\n\nUpload geometries to be used as trained data by your AI model\n\nAssign those data to your project\n\nConfigure your AI model according to the data\n\nBuild your AI model\n\nGenerate new designs with previously built AI models\n\nExport those geometries to check if they correspond to your expectations\n\nStart with a small number of training geometries and the debug build preset to quickly check if the model can learn and if the generated designs are meaningful.\n\nThis helps detect issues early and saves time.\n\nIf the model performs well on the small set, you can try the other build presets:\nshort, default, long, depending on the complexity of the geometries used as training data.\n\nFor practical examples and scripts to execute yourself, see ref_examples.\n\n"},{"objectID":"User guide","href":"user_guide.html#user-guide","title":"User guide","text":"User guide\n\n"},{"objectID":"API reference","href":"api_reference/client.html#client","title":"API reference > Client","text":"Client\n\n\n\n\n\nclass SimAIClient(**kwargs)\n\nProvides the client for communicating with the SimAI API.\n\nFor keyword arguments, see the ClientConfig class.\n\nExample\n\n\n\nclassmethod from_config(profile: str = 'default', path: Path | str | PathLike | None = None, **kwargs) -> SimAIClient\n\nInitializes a SimAI client by reading a configuration file.\n\nYou can provide the path of the configuration file to load. If no path is\ngiven, this method looks at the default locations.\n\nFor more information, see Configuration file.\n\nYou can use kwargs to override part of the configuration.\n\nParameters\n\nprofile (str) – Profile to load from the configuration file. The default profile\nis loaded if no profile is provided.\n\npath (Path | str | PathLike | None) – Path for the configuration file.\n\n**kwargs – Additional arguments to pass to the SimAI client.\n\nReturns\n\nConfigured client.\n\nRaises\n\nConfigurationNotFoundError – No configuration file was found at the given location\n    or in the default profile if no path was given.\n\nInvalidConfigurationError – Configuration is invalid or incomplete.\n\nReturn type\n\nSimAIClient\n\nExample\n\nCreate the client after setting up your configuration file..\n\nThe default paths are only supported on Unix systems.\n\n\n\nset_current_project(name: str)\n\nSet the current project for the SimAI client.\n\nThis method affects how some methods related to projects or associated\ndata behave.\n\nParameters\n\nname (str) – Name of the project that the client should switch to.\n\n\n\nset_current_workspace(name: str)\n\nSet the current workspace for the SimAI client.\n\nParameters\n\nname (str) – Name of the workspace that the client should switch to.\n\nExample\n\n\n\nwait() -> None\n\nWait for all ongoing operations on locally known predictions and postprocessings\nto finish.\n\nRaises\n\nSimAIError – If something went wrong on an operation.\n\nMultipleErrors – If things went wrong on multiple operations.\n\n\n\nproperty current_project: Project\n\nProject currently used by the SimAPI client.\n\nYou should not set the project directly. Instead, use the set_current_project()\nmethod, which uses the project name and ensures that the project exists.\n\n\n\nproperty current_workspace: Workspace\n\nWorkspace currently used by the SimAI client.\n\nYou should not set the workspace directly. Instead, use the set_current_workspace()\nmethod, which uses the workspace name and ensures that the workspace exists.\n\n\n\nproperty geomai: GeomAIClient\n\nAccess the GeomAI client.\n\n\n\nproperty geometries\n\nRepresentation of all geometries on the server.\nFor more information, see geometries.\n\n\n\nproperty me: CurrentUser\n\nAccess current user self-management operations.\n\nThis property provides methods to manage the current user’s account,\nincluding generating offline tokens and managing consents.\n\nExample\n\n\n\nproperty models\n\nRepresentation of all models on the server.\nFor more information, see models.\n\n\n\nproperty optimizations\n\nRepresentation of all optimizations on the server.\nFor more information, see optimizations.\n\n\n\nproperty post_processings\n\nRepresentation of all postprocessings on the server.\nFor more information, see post_processings.\n\n\n\nproperty predictions\n\nRepresentation of all predictions on the server.\nFor more information, see predictions.\n\n\n\nproperty projects\n\nRepresentation of all projects on the server.\nFor more information, see projects.\n\n\n\nproperty training_data\n\nRepresentation of all training data on the server.\nFor more information, see training_data.\n\n\n\nproperty training_data_parts\n\nRepresentation of all training data parts on the server.\nFor more information, see training_data_parts.\n\n\n\nproperty workspaces\n\nRepresentation of all workspaces on the server.\nFor more information, see workspaces."},{"objectID":"API reference","href":"api_reference/geomai/training_data.html#geomaitrainingdata","title":"API reference > GeomAITrainingData","text":"GeomAITrainingData\n\n\n\nA GeomAITrainingData instance is a\ncollection of GeomAITrainingDataPart\ninstances representing a geometry that can be used as input for the training of models.\nIn most cases it will contain a single part: the geometry to train on.\n\nThe formats supported as input are .vtp and .stl.\n\nThe geometry used as input must be:\n\nwatertight geometry.\n\nmanifold geometry.\n\nIt must not intersect with itself (no self-penetration)."},{"objectID":"API reference","href":"api_reference/geomai/training_data.html#directory","title":"API reference > GeomAITrainingData > Directory","text":"Directory\n\n\n\nclass GeomAITrainingDataDirectory\n\nProvides a collection of methods related to training data.\n\nThis class is accessed through client.training_data.\n\nExample\n\nList all of the GeomAI training data:\n\n\n\n\n\ncreate(name: str, project: GeomAIProject | str | None = None) -> GeomAITrainingData\n\nCreate an empty GeomAITrainingData object.\n\nParameters\n\nname (str) – Name to give the new GeomAITrainingData object.\n\nproject (GeomAIProject | str | None) – Project object to associate the data with.\n\nReturns\n\nCreated GeomAITrainingData object.\n\nReturn type\n\nGeomAITrainingData\n\ncreate_from_file() handles all the creation of training data and parts for you\n\n\n\ncreate_from_file(file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], project: GeomAIProject | str | None = None, monitor_callback: Callable[[int], None] | None = None) -> GeomAITrainingData\n\nConvenience function to create a GeomAITrainingData object from a file.\n\nParameters\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nproject (GeomAIProject | str | None) – Optional project to attach the training data to.\nDefaults to the configured project if any.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\n\n\ndelete(training_data: GeomAITrainingData | str) -> None\n\nDelete a GeomAITrainingData object and its associated parts from the server.\n\nParameters\n\ntraining_data (GeomAITrainingData | str) – ID or model object of the GeomAITrainingData object.\n\n\n\nget(id: str | None = None, name: str | None = None) -> GeomAITrainingData\n\nGet a specific GeomAITrainingData object from the server.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the training data.\n\nname (str | None) – Name of the training data.\n\nReturns\n\nGeomAITrainingData\n\nRaises\n\nNotFoundError – No training data with the given ID exists.\n\nReturn type\n\nGeomAITrainingData\n\n\n\niter(filters: dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], Any]] | list[RawSingleFilter] | None = None) -> SizedIterator[GeomAITrainingData]\n\nIterate over all GeomAITrainingData objects on the server.\n\nParameters\n\nfilters (dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], ~typing.Any]] | list[~ansys.simai.core.data.types.RawSingleFilter] | None) – Optional Filters to apply.\n\nReturns\n\nIterator over all GeomAITrainingData objects on the server.\n\nReturn type\n\nSizedIterator[GeomAITrainingData]\n\n\n\nlist(filters: dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], Any]] | list[RawSingleFilter] | None = None) -> List[GeomAITrainingData]\n\nList all GeomAITrainingData objects on the server.\n\nThis can take a very long time, consider using iter() instead.\n\nParameters\n\nfilters (dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], ~typing.Any]] | list[~ansys.simai.core.data.types.RawSingleFilter] | None) – Optional Filters to apply.\n\nReturns\n\nList of all GeomAITrainingData objects on the server.\n\nReturn type\n\nList[GeomAITrainingData]\n\n\n\nupload_part(training_data: GeomAITrainingData | str, file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], monitor_callback: Callable[[int], None] | None = None) -> GeomAITrainingDataPart\n\nAdd a part to a GeomAITrainingData object.\n\nParameters\n\ntraining_data (GeomAITrainingData | str) – ID or model object of the training data to\nadd the part to.\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the upload.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nAdded GeomAITrainingDataPart object.\n\nReturn type\n\nGeomAITrainingDataPart"},{"objectID":"API reference","href":"api_reference/geomai/training_data.html#model","title":"API reference > GeomAITrainingData > Model","text":"Model\n\n\n\nclass GeomAITrainingData\n\nProvides the local representation of a training data object.\n\n\n\n\n\nadd_to_project(project: GeomAIProject | str)\n\nAdd the training data to a GeomAIProject object.\n\nParameters\n\nproject (GeomAIProject | str) – ID or model object of the project to add the data to.\n\n\n\ndelete() -> None\n\nDelete the training data on the server.\n\n\n\n\n\nextract_data() -> None\n\nExtract or reextract the data from a training data.\n\nData should be extracted from a training data once all its parts have been fully uploaded.\nThis is done automatically when using GeomAITrainingDataDirectory.create_from_file() to create training data.\n\nData can only be reextracted from a training data if the extraction previously failed or if new files have been added.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nremove_from_project(project: GeomAIProject | str)\n\nRemove the training data from a GeomAIProject object.\n\nParameters\n\nproject (GeomAIProject | str) – ID or model of the project to remove data from.\n\nRaises\n\nansys.simai.core.errors.ApiClientError – If the data is the project’s sample.\n\nansys.simai.core.errors.ApiClientError – If the project is in training.\n\n\n\nupload_part(file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], monitor_callback: Callable[[int], None] | None = None) -> GeomAITrainingDataPart\n\nAdd a part to the training data.\n\nParameters\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nCreated GeomAITrainingDataPart.\n\nReturn type\n\nGeomAITrainingDataPart\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty extracted_metadata: Dict | None\n\nMetadata extracted from the training data.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty name: str\n\nName of the training data.\n\n\n\nproperty parts: List[GeomAITrainingDataPart]\n\nList of all parts\nobjects in the training data."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#how-to-configure-the-non-parametric-optimization","title":"User guide > How to configure the non-parametric optimization","text":"How to configure the non-parametric optimization\n\nLearn about the parameters to set when configuring the non-parametric optimization.\nFor more information about using those parameters, see optimizations."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#baseline-geometry-geometry","title":"User guide > How to configure the non-parametric optimization > Baseline geometry (geometry)","text":"Baseline geometry (geometry)\n\nThe baseline geometry should be chosen carefully, as it forms the foundation for the optimization process.\nIt is recommended to select a geometry that is representative of your dataset to ensure that the optimization produces relevant results.\n\nThe supported input formats are vtp, stl, zip and cgns.\n\nIf the optimization does not show improvement after several optimization processes,\ntry using a different geometry from the training data as the baseline (geometry).\nAlways make sure the geometry is clean and of high quality, as issues like mesh errors can negatively impact the optimization process."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#bounding-boxes","title":"User guide > How to configure the non-parametric optimization > Bounding boxes","text":"Bounding boxes\n\nBounding boxes can be obtained from any CAD tool (for example, Ansys SpaceClaim).\nBounding boxes define the regions where deformations can occur during optimization.\n\nA good starting point is to use the bounding boxes that cover the areas most likely to influence performance improvements.\nIf the optimization results do not improve, you can increase the size of the boxes to allow more flexibility or add additional boxes for finer control.\nHowever, avoid using excessively large boxes, as they can lead to unrealistic or unstable deformations that do not make sense physically.\n\nExamples of bounding boxes:\n\n\n\n\n\n\n\n\n\n\n\n"},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#symmetries","title":"User guide > How to configure the non-parametric optimization > Symmetries","text":"Symmetries\n\nSymmetry constraints help reduce computational costs and ensure physically consistent results if you are looking for symmetrical optimizations.\n\nSymmetry can be planar or axial:\n\nPlanar symmetry (symmetries parameter)\nensures that the geometry is mirrored across a plane normal to the given direction,\nwhich is useful for designs that are identical on both sides of a plane. For example,\nif the design has a planar symmetry based on the “YZ” plane, then “X” is the parameter to specify.\n\nAxial symmetry (axial_symmetry parameter)\nshould be chosen when the deformation needs to be equal around a specific axis,\nresulting in rotational symmetry."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#scalars","title":"User guide > How to configure the non-parametric optimization > Scalars","text":"Scalars\n\nThe values of the scalars should remain consistent with those defined in your model configuration,\nso the scalars parameter must correspond to the ones defined in the SimAI workspace.\nFrequent changes to scalars can create inconsistencies and reduce the reliability of optimization results.\nMake adjustments only when necessary to maintain a stable and physically realistic simulation environment."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#number-of-iterations-n_iters","title":"User guide > How to configure the non-parametric optimization > Number of iterations (n_iters)","text":"Number of iterations (n_iters)\n\nThe number of iterations determines how many rounds of improvement will be executed in one optimization process.\nFor quick tests, 5 iterations are usually sufficient.\nIf convergence is slow or the optimum remains unstable, consider increasing the number of iterations to 100 or more.\nBefore committing to long runs, you should monitor the convergence trend to ensure additional iterations will provide value rather than waste computation time."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#objective-minimize-or-maximize","title":"User guide > How to configure the non-parametric optimization > Objective: Minimize or Maximize","text":"Objective: Minimize or Maximize\n\nWhen defining an objective, focus on the most relevant performance indicator, for example, minimizing drag or maximizing lift.\nFor non-parametric optimization, only one objective can be defined."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#maximum-displacement","title":"User guide > How to configure the non-parametric optimization > Maximum displacement","text":"Maximum displacement\n\nThe max_displacement parameter is optional. It controls the allowable deformation for each bounding box.\nIt is calculated from the baseline geometry and applied to the entire optimization.\n\nIf you want to use the max_displacement parameter, you must set one per bounding box defined.\nIf you want to use a different maximum displacement parameter for each box, you must list them in the same order as the bounding boxes.\nFor example, for two bounding boxes:\n\nIts unit must correspond to the geometry coordinates unit.\nFor example, if the bounding box is 2 meters long, the maximum displacement should be specified in meters as well.\n\nSetting this value too high leads to an error that returns the maximum possible value based on the optimization parameters,\nwhile values that are too low may overly restrict the optimization.\n\nA practical guideline is to limit displacement to a small percentage of the geometry’s characteristic length for each bounding box.\nThis ensures that the optimized geometry remains physically realistic while still allowing meaningful shape changes."},{"objectID":"User guide","href":"user_guide/automorphing/configure_automorphing.html#show-progress","title":"User guide > How to configure the non-parametric optimization > Show progress","text":"Show progress\n\nThe show_progress parameter determines whether progress updates are displayed during the optimization run.\nIt is generally recommended to enable this feature during development and testing phases\nso that you can monitor the process and detect potential issues early."},{"objectID":"Home","href":"_examples/01_pysimai_ex/00-model_configuration_reuse.html#model-configuration-reuse","title":"Model configuration reuse","text":"Model configuration reuse\n\nThis example demonstrates how to retrieve the latest model configuration\nof a project and use it to launch a model build in another project."},{"objectID":"Home","href":"_examples/01_pysimai_ex/00-model_configuration_reuse.html#import-necessary-libraries","title":"Model configuration reuse > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/01_pysimai_ex/00-model_configuration_reuse.html#create-a-project-and-allocate-training-data","title":"Model configuration reuse > Create a project and allocate training data","text":"Create a project and allocate training data\n\nDefine the project name.\n\nCreate the project.\n\nSet the names of the data samples to be associated with the created project.\n\nRetrieve the desired training data samples and associate them with\nthe new project."},{"objectID":"Home","href":"_examples/01_pysimai_ex/00-model_configuration_reuse.html#select-a-model-configuration-and-associate-it-with-the-newly-created-project","title":"Model configuration reuse > Select a model configuration and associate it with the newly created project","text":"Select a model configuration and associate it with the newly created project\n\nRetrieve the model configuration from another project that you wish to reuse.\n\nIf the new project meets the requirements for training, associate\nthe project’s ID with the configuration and launch a model build.\n\n\n\nDownload Jupyter notebook: 00-model_configuration_reuse.ipynb\n\nDownload Python source code: 00-model_configuration_reuse.py\n\nDownload zipped: 00-model_configuration_reuse.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"User guide","href":"user_guide/pysimai_ug/index.html#run-a-physics-prediction","title":"User guide > Run a physics prediction","text":"Run a physics prediction\n\nThese sections teach you how to use particular features of PySimAI.\n\n"},{"objectID":"API reference","href":"api_reference/geomai/training_data_parts.html#geomaitrainingdataparts","title":"API reference > GeomAITrainingDataParts","text":"GeomAITrainingDataParts\n\n\n\nA GeomAITrainingDataPart instance\nis a singular file that is part of a GeomAITrainingData\ninstance.\n\nIt is strongly recommended to use\nGeomAITrainingData.create_file\ninstead of interacting with parts directly."},{"objectID":"API reference","href":"api_reference/geomai/training_data_parts.html#directory","title":"API reference > GeomAITrainingDataParts > Directory","text":"Directory\n\n\n\nclass GeomAITrainingDataPartDirectory\n\nProvides the collection of methods related to GeomAI training data parts.\n\nThis class is accessed through client.geomai.training_data_parts.\n\n\n\n\n\nget(id: str) -> GeomAITrainingDataPart\n\nGet a GeomAITrainingDataPart object from the server.\n\nParameters\n\nid (str) – ID of the training data part.\n\nReturns\n\nGeomAITrainingDataPart instance with the given ID if it exists.\n\nRaises\n\nNotFoundError – No prediction with the given ID exists.\n\nReturn type\n\nGeomAITrainingDataPart"},{"objectID":"API reference","href":"api_reference/geomai/training_data_parts.html#model","title":"API reference > GeomAITrainingDataParts > Model","text":"Model\n\n\n\nclass GeomAITrainingDataPart\n\nProvides the local representation of a GeomAI training data part object.\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty name: str\n\nName of the file.\n\n\n\nproperty size: int\n\nSize of the file in bytes."},{"objectID":"Computation times","href":"sg_execution_times.html#computation-times","title":"Computation times","text":"Computation times\n\n00:00.000 total execution time for 11 files from all galleries:\n\n\n\n\n\n\n\nExample\n\nTime\n\nMem (MB)\n\nsphx_glr__examples_00_basic_simai_ex_00-create_project_upload_data.py (examples/00_basic_simai_ex/00-create_project_upload_data.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_00_basic_simai_ex_01-build_model.py (examples/00_basic_simai_ex/01-build_model.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_00_basic_simai_ex_02-run_predictions.py (examples/00_basic_simai_ex/02-run_predictions.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_00-model_configuration_reuse.py (examples/01_pysimai_ex/00-model_configuration_reuse.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_01-model_recomputation.py (examples/01_pysimai_ex/01-model_recomputation.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_02-subset_assignment.py (examples/01_pysimai_ex/02-subset_assignment.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_03-list_based_subset_assignment.py (examples/01_pysimai_ex/03-list_based_subset_assignment.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_00-create_project_upload_data.py (examples/02_generative_design_ex/00-create_project_upload_data.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_01-build_model.py (examples/02_generative_design_ex/01-build_model.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_02-generate_random_geometries.py (examples/02_generative_design_ex/02-generate_random_geometries.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_03-interpolate_geometries.py (examples/02_generative_design_ex/03-interpolate_geometries.py)\n\n00:00.000\n\n0.0"},{"objectID":"API reference","href":"api_reference/post_processings.html#postprocessings","title":"API reference > Postprocessings","text":"Postprocessings\n\n"},{"objectID":"API reference","href":"api_reference/post_processings.html#directory","title":"API reference > Postprocessings > Directory","text":"Directory\n\n\n\nclass PostProcessingDirectory(client: ansys.simai.core.client.SimAIClient)\n\n\n\n\n\ndelete(post_processing: PostProcessing | str)\n\nDelete a postprocessing.\n\nParameters\n\npost_processing (PostProcessing | str) – ID or model of the postprocessing.\n\n\n\nget(id: str) -> PostProcessing\n\nGet a specific postprocessing object from the server.\n\nParameters\n\nid (str) – ID of the postprocessing.\n\nReturns\n\nPostProcessing with the given ID if it exists.\n\nRaises\n\nNotFoundError – No postprocessing with the given ID exists.\n\nReturn type\n\nPostProcessing\n\n\n\nlist(post_processing_type: Type[PostProcessing] | None = None, prediction: Prediction | str | None = None, workspace: Workspace | str | None = None) -> List[PostProcessing]\n\nList the postprocessings in the current workspace or associated with a prediction.\n\nOptionally you can choose to list only postprocessings of a specific type.\nFor the name of the available postprocessings, see available_pp.\n\nParameters\n\npost_processing_type (Type[PostProcessing] | None) – Type of postprocessing to list.\n\nprediction (Prediction | str | None) – ID or model of a prediction.\nIf a value is specified, only postprocessings associated with this prediction\nare returned.\n\nworkspace (Workspace | str | None) – ID or model of a workspace.\nIf a value is specified, only postprocessings associated with this workspace\nare returned.\n\nRaises\n\nNotFoundError – Postprocessing type, prediction ID or workspace ID are incorrect.\n\nInvalidArguments – If both prediction and workspace are specified.\n\nInvalidClientStateError – Neither prediction nor workspace are defined, default\n    workspace is not set.\n\nExample\n\n\n\nrun(post_processing_type: str | Type[PostProcessing], prediction: Prediction | str, parameters: Dict[str, Any] | None = None, **kwargs) -> PostProcessing\n\nRun a postprocessing on a prediction.\n\nFor the name and the parameters expected by the postprocessings,\nsee available_pp and pp_methods. Note that the case\nof the class names must be respected.\n\nParameters\n\npost_processing_type (str | Type[PostProcessing]) – Type of postprocessing to run as a string\nor as the class itself.\n\nprediction (Prediction | str) – ID or model of the prediction\nto run the postprocessing for.\n\nparameters (Dict[str, Any] | None) – Parameters to apply to the postprocessing, if needed.\nAlternatively, parameters can be passed as kwargs.\n\n**kwargs – Unpacked parameters for the postprocessing.\n\nExamples\n\nUsing kwargs:\n\n\n\nproperty info: List[Dict[str, Any]]\n\nDictionary containing information about the available postprocessings and their parameters.\n\nExample"},{"objectID":"API reference","href":"api_reference/post_processings.html#model","title":"API reference > Postprocessings > Model","text":"Model\n\n\n\nclass PostProcessing\n\nProvides the local representation of a PostProcessing object.\n\nThis is an abstract class. Depending on the postprocessing, a different implementation\nis returned. For more information, see available_pp.\n\n\n\ndelete()\n\nDelete the postprocessing and its result data.\n\nRaises\n\nNotFoundError – If the postprocessing has already been deleted.\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nabstract property data\n\nGet the data generated by the postprocessing.\n\nThe return type may vary depending on the postprocessing. It can be a dictionary\nor, if the data is binary, a DownloadableResult object, which provides\nhelpers to download the data into a file or in memory.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty parameters: Dict[str, Any] | None\n\nParameters used to run the postprocessing.\n\n\n\nproperty prediction: Prediction\n\nParent prediction.\n\nThe parent prediction is queried if it is not already known by the current SimAPI client session.\n\nprediction_id: Get the parent prediction’s ID without query.\n\n\n\nproperty prediction_id: str\n\nParent prediction’s ID.\n\nprediction: Get the parent prediction.\n\n\n\nproperty type: str\n\nType of postprocessing that this object represents.\n\n"},{"objectID":"API reference","href":"api_reference/post_processings.html#nested-prediction-namespace","title":"API reference > Postprocessings > Nested prediction namespace","text":"Nested prediction namespace\n\n\n\nclass PredictionPostProcessings\n\nActs as the namespace inside Prediction objects.\n\nThis class allows you to analyze the results of a prediction.\n\nIt can be accessed from any prediction object through its\npost property:\n\nExample\n\n\n\n\n\ncustom_volume_point_cloud(run: bool = True) -> CustomVolumePointCloud | None\n\nCompute or get the result of a predicted volume depending on the geometry’s point cloud.\n\nThis is a non-blocking method. It returns the CustomVolumePointCloud\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nCustomVolumePointCloud object that allows downloading the binary data.\n\nReturn type\n\nCustomVolumePointCloud | None\n\nExamples\n\nRun and download a custom volume point cloud\n\n\n\nglobal_coefficients(run: bool = True) -> GlobalCoefficients | None\n\nCompute or get the global coefficients of the prediction.\n\nThis is a non-blocking method. It returns the GlobalCoefficients\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nComputation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nGlobalCoefficients object that eventually contains\nthe global coefficients with its pressure and velocity components.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nGlobalCoefficients | None\n\n\n\nlist(post_processing_type: Type[PostProcessing] | None = None) -> List[PostProcessing]\n\nList the postprocessings associated with the prediction.\n\nSee post_processings.list\n\n\n\n\n\npredict_scalars(run: bool = True) -> PredictScalars | None\n\nCompute or get the predicted scalars of the prediction.\n\nThis is a non-blocking method. It returns the PredictScalars\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nComputation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nPredictScalars object that eventually contains\nthe predicted scalars with its pressure and velocity components.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nPredictScalars | None\n\n\n\nslice(axis: str, coordinate: float, format: str = 'png', run: bool = True) -> Slice | None\n\nCompute or get a slice for specific plane parameters.\n\nThis is a non-blocking method. It returns the Slice\nobject without waiting. This object may not have data right away\nif computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method\nwith a specific set of parameters. Subsequent calls with the same\nparameters do not relaunch it.\n\nThe slice is in the NPZ format.\n\nParameters\n\naxis (str) – Axis to slice.\n\ncoordinate (float) – Coordinate along the given axis to slice at.\n\nformat (str) – Format of the output. The default is 'png'. Options\nare 'png' and 'vtp'.\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nSlice object that allows downloading the binary data.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nSlice | None\n\nExample\n\nMake a slice and open it in a new window using the Pillow\nlibrary.\n\n\n\nsurface_evolution(axis: str, delta: float, run: bool = True) -> SurfaceEvolution | None\n\nCompute or get the SurfaceEvolution for specific parameters.\n\nThis is a non-blocking method. It returns the SurfaceEvolution\nobject without waiting. This object may not have data right away\nif computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method\nwith a specific set of parameters. Subsequent calls with the\nsame parameters do not relaunch it.\n\nParameters\n\naxis (str) – Axis to compute the surface evolution for.\n\ndelta (float) – Increment of the abscissa in meters.\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nSurfaceEvolution that allows access to the values.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nSurfaceEvolution | None\n\n\n\nsurface_vtp(run: bool = True) -> SurfaceVTP | None\n\nCompute or get the result of the prediction’s surface in VTP format.\n\nThis method associates all data with cells; if a variable is originally\nassociated with points in the sample, it would be now associated with cells.\n\nIt is a non-blocking method. It returns the PostProcessingVTP\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nSurfaceVTP object that allows downloading the binary data.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nSurfaceVTP | None\n\nExamples\n\nRun and download a surface VTP with data associated with cells.\n\nRun a surface VTP with data association on cells, and open a plot using PyVista.\n\n\n\nsurface_vtp_td_location(run: bool = True) -> SurfaceVTPTDLocation | None\n\nCompute or get the result of the prediction’s surface in VTP format .\n\nThis method keeps the original data association as they are in the sample.\n\nIt is a non-blocking method. It returns the PostProcessingVTP\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nSurfaceVTPTDLocation object that allows downloading the binary data.\nReturns None if run=False and the postprocessing does not exist.\n\nReturn type\n\nSurfaceVTPTDLocation | None\n\nExamples\n\nRun and download a surface VTP with the original data association.\n\nRun a surface VTP with the original data association, and open a plot using PyVista.\n\n\n\nvolume_vtu(run: bool = True) -> VolumeVTU | None\n\nCompute or get the result of the prediction’s volume in VTU format.\n\nThis is a non-blocking method. It returns the PostProcessingVTU\nobject without waiting. This object may not have data right away\nif the computation is still in progress. Data is filled\nasynchronously once the computation is finished.\nThe state of computation can be monitored with the is_ready flag\nor waited upon with the wait() method.\n\nThe computation is launched only on first call of this method.\nSubsequent calls do not relaunch it.\n\nParameters\n\nrun (bool) – Boolean indicating whether to compute or get the postprocessing.\nThe default is True. If False, the postprocessing is not\ncomputed, and None is returned if it does not exist yet.\n\nReturns\n\nVolumeVTU object that allows downloading the binary data.\n\nReturn type\n\nVolumeVTU | None\n\nExamples\n\nRun and download a volume VTU\n\nRun a volume VTU and open a plot using PyVista.\n\n"},{"objectID":"API reference","href":"api_reference/post_processings.html#available-postprocessings","title":"API reference > Postprocessings > Available postprocessings","text":"Available postprocessings\n\nDepending on the capabilities of your model, some of these objects may not\nbe available in your workspace. You can use the\ninfo() method\nto see which ones are available.\n\n\n\nclass GlobalCoefficients\n\nProvides the representation of the global coefficients of a prediction.\n\nThe data attribute contains a dictionary representing the global coefficients\nwith its pressure and velocity components.\n\nThis class is generated through the PredictionPostProcessings.global_coefficients()\nmethod.\n\n\n\nexport(format: str | None = 'json') -> DownloadableResult\n\nExport the postprocessing results in the desired format.\n\nAccessing this property blocks until the data is ready.\n\nParameters\n\nformat (str | None) – Format to export the data in. The default is 'json'.\nOptions are 'csv.zip', 'json', and 'xlsx'. Note that\nthe 'csv.zip' option exports a ZIP file containing\nmultiple CSV sheets.\n\nReturns\n\nDownloadableResult object for downloading the exported\ndata into a file or access it in memory.\n\nReturn type\n\nDownloadableResult\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty data: Dict[str, List]\n\nDictionary containing the global coefficients, including pressure\nand velocity components.\n\nAccessing this property blocks until the data is ready.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nclass PredictScalars\n\nProvides the representation of the predicted scalars of a prediction.\n\nThe data attribute contains a dictionary representing the predicted scalars.\n\nThis class is generated through the PredictionPostProcessings.predict_scalars()\nmethod.\n\n\n\nexport(format: str | None = 'json') -> DownloadableResult\n\nExport the postprocessing results in the desired format.\n\nAccessing this property blocks until the data is ready.\n\nParameters\n\nformat (str | None) – Format to export the data in. The default is 'json'.\nOptions are 'csv.zip', 'json', and 'xlsx'. Note that\nthe 'csv.zip' option exports a ZIP file containing\nmultiple CSV sheets.\n\nReturns\n\nDownloadableResult object for downloading the exported\ndata into a file or access it in memory.\n\nReturn type\n\nDownloadableResult\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty data: Dict[str, List]\n\nDictionary containing the predicted scalars.\n\nAccessing this property blocks until the data is ready.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nclass SurfaceEvolution\n\nProvides the representation of the SurfaceEvolution object.\n\nThis class is generated through PredictionPostProcessings.surface_evolution()\n\n\n\nas_dict() -> Dict[str, Any]\n\nDownload the SurfaceEvolution JSON data and load it as a Python dictionary.\n\nAccessing this help method blocks until the data is ready.\n\n\n\n\n\nexport(format: str | None = 'json') -> DownloadableResult\n\nExport the postprocessing results in the desired format.\n\nAccessing this property blocks until the data is ready.\n\nParameters\n\nformat (str | None) – Format to export the data in. The default is 'json'.\nOptions are 'csv.zip', 'json', and 'xlsx'. Note that\nthe 'csv.zip' option exports a ZIP file containing\nmultiple CSV sheets.\n\nReturns\n\nDownloadableResult object for downloading the exported\ndata into a file or access it in memory.\n\nReturn type\n\nDownloadableResult\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty data: DownloadableResult\n\nDownloadableResult object that allows access to the\nSurfaceEvolution JSON data, both directly in memory any by downloading it\ninto a file.\n\nAccessing this property blocks until the data is ready.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nclass Slice\n\nProvides a representation of a slice from the prediction in PNG or VTP format.\n\nThis class is generated through the PredictionPostProcessings.slice() method.\n\n\n\nproperty data: DownloadableResult\n\nDownloadableResult object that allows\naccess to slice data, both directly in memory\nand by downloading it into a file.\n\nAccessing this property blocks until the data is ready.\n\nReturns\n\nA DownloadableResult\n\n\n\nclass SurfaceVTP\n\nExports the surface of the prediction in VTP format associating all data with cells.\n\nThis class is generated through the surface_vtp() method.\n\n\n\nclass SurfaceVTPTDLocation\n\nExports the surface of the prediction in VTP format keeping the original data association.\n\nThis class is generated through the surface_vtp_td_location() method.\n\n\n\nclass VolumeVTU\n\nProvides for exporting the volume of the prediction in VTU format.\n\nThis class is generated through the PredictionPostProcessings.volume_vtu() method.\n\n\n\nclass CustomVolumePointCloud\n\nProvides a representation of a CustomVolumePointCloud post-processing.\n\nThis class is generated through the custom_volume_point_cloud() method.\n\n\n\nproperty data: DownloadableResult\n\nDownloadableResult object that allows access to the custom volume VTP\neither directly in memory or by download it into a file.\n\nAccessing this property blocks until the data is ready"},{"objectID":"API reference","href":"api_reference/post_processings.html#helpers","title":"API reference > Postprocessings > Helpers","text":"Helpers\n\n\n\nclass DownloadableResult\n\nProvides the object representing a result data for a postprocessing in binary format.\n\n\n\n\n\ndownload(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike) -> None\n\nDownload the postprocessing data to the specified file or path.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike) – Binary file-object or path of the file to download the data into.\n\n\n\nin_memory() -> BytesIO\n\nLoad the postprocessing data in memory.\n\nReturns\n\nio.BytesIO object containing the postprocessing data.\n\nReturn type\n\nBytesIO"},{"objectID":"API reference","href":"api_reference/geomai/models.html#geomaimodels","title":"API reference > GeomAIModels","text":"GeomAIModels\n\n\n\nTo build a GeomAI model, use GeomAIProject.build_model."},{"objectID":"API reference","href":"api_reference/geomai/models.html#directory","title":"API reference > GeomAIModels > Directory","text":"Directory\n\n\n\nclass GeomAIModelDirectory\n\nProvides a collection of methods related to building models.\n\n\n\n\n\nbuild(project: GeomAIProject | str, configuration: dict | GeomAIModelConfiguration) -> GeomAIModel\n\nLaunches a GeomAI build with the given configuration.\n\nParameters\n\nproject (GeomAIProject | str) – The GeomAI project in which to run the training.\n\nconfiguration (dict | GeomAIModelConfiguration) – a GeomAIModelConfiguration object that contains the properties to be used in the build.\n\nExamples\n\nUse a previous configuration for a new build in the same project:\n\nUse a previous configuration for a new build in another project:"},{"objectID":"API reference","href":"api_reference/geomai/models.html#model","title":"API reference > GeomAIModels > Model","text":"Model\n\n\n\nclass GeomAIModel\n\nGeomAI model representation.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty configuration: GeomAIModelConfiguration\n\nBuild configuration of a model.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty project_id: str\n\nThe ID of the GeomAI project where the model exists."},{"objectID":"API reference","href":"api_reference/geomai/models.html#geomaimodelconfiguration","title":"API reference > GeomAIModels > GeomAIModelConfiguration","text":"GeomAIModelConfiguration\n\n\n\npydantic model GeomAIModelConfiguration\n\nRaises InvalidArguments if the input data cannot be validated to from a valid model.\n\n\n\nfield build_preset: Literal['debug', 'short', 'default', 'long'] | None = None\n\nThe preset to use for the model training duration. One of debug, short, default, long.\n\ndebug: 4 minutes + 15 sec per geometry.\n\nshort: 45 minutes + 15 sec per geometry.\n\ndefault: 3 hours + 15 sec per geometry.\n\nlong: 15 hours + 15 sec per geometry.\n\nMutually exclusive with nb_epochs.\n\n\n\nfield nb_epochs: int | None = None\n\nThe number of times each training data is seen by the model during the training, between 1 and 1000.\n\nMutually exclusive with build_preset.\n\n\n\nfield nb_latent_param: int = 512\n\nAn optional integer that defines the dimension of the latent space between 2 and 1024.\n\nThe default value of 512 is highly recommended if you are a non-expert user.\n\nIf you are an expert user, ready to experiment and assess correctly your models performance for different latent parameter value,\nand your use case has specific constraints, you can change this parameter, keeping the following in mind:\n\nIf the number is too low, geometries might become too coarse, and the reconstruction performance might degrade.\n\nIf the number is too high, the model will not be able to generate new geometries correctly.\n\nThe default value of 512 is used if nb_latent_param is not set."},{"objectID":"API reference","href":"api_reference/geomai/predictions.html#geomaipredictions","title":"API reference > GeomAIPredictions","text":"GeomAIPredictions\n\n\n\nThe Prediction module is in charge of running the GeomAI-powered\npredictions in your workspaces."},{"objectID":"API reference","href":"api_reference/geomai/predictions.html#directory","title":"API reference > GeomAIPredictions > Directory","text":"Directory\n\n\n\nclass GeomAIPredictionDirectory\n\nProvides a collection of methods related to GeomAI model predictions.\n\nThis method is accessed through client.geomai.predictions.\n\nExample\n\n\n\n\n\ndelete(prediction: GeomAIPrediction | str) -> None\n\nDelete a specific GeomAI prediction from the server.\n\nParameters\n\nprediction (GeomAIPrediction | str) – ID or model of the prediction.\n\nRaises\n\nNotFoundError – No prediction with the given ID exists.\n\n\n\ndownload(prediction: GeomAIPrediction | str, file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the file generated by the prediction.\n\nThe downloaded file will be in the VTP format.\n\nParameters\n\nprediction (GeomAIPrediction | str) – ID or model of the prediction.\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\nConsider using GeomAIPrediction.download() instead which will wait for the\n\nprediction to be ready instead of throwing an error if it’s not.\n\n\n\nget(id: str) -> GeomAIPrediction\n\nGet a specific GeomAI prediction object from the server by ID.\n\nParameters\n\nid (str) – ID of the prediction.\n\nReturns\n\nGeomAIPrediction instance with the given ID if it exists.\n\nRaises\n\nNotFoundError – No prediction with the given ID exists.\n\nReturn type\n\nGeomAIPrediction\n\n\n\nlist(workspace: GeomAIWorkspace | str | None = None) -> List[GeomAIPrediction]\n\nList all GeomAI predictions on the server that belong to the specified workspace or the configured one.\n\nParameters\n\nworkspace (GeomAIWorkspace | str | None) – ID or model of the workspace to list the predictions for.\nThis parameter is necessary if no workspace is set for the client.\n\n\n\nrun(configuration: GeomAIPredictionConfiguration | dict[str, Any], workspace: GeomAIWorkspace | str | None = None) -> GeomAIPrediction\n\nRun a prediction in the given workspace with the given configuration.\n\nParameters\n\nconfiguration (GeomAIPredictionConfiguration | dict[str, Any]) – The configuration to run the prediction with.\n\nworkspace (GeomAIWorkspace | str | None) – Optional ID or model of the target workspace.\nDefaults to the current workspace if set.\n\nReturns\n\nCreated prediction object.\n\nRaises\n\nProcessingError – If the server failed to process the request.\n\nReturn type\n\nGeomAIPrediction\n\nExamples"},{"objectID":"API reference","href":"api_reference/geomai/predictions.html#model","title":"API reference > GeomAIPredictions > Model","text":"Model\n\n\n\nclass GeomAIPrediction\n\nProvides the local representation of a GeomAI prediction object.\n\n\n\n\n\ndelete() -> None\n\nRemove a prediction from the server.\n\n\n\n\n\ndownload(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the file generated by the prediction.\n\nThe downloaded file will be in the VTP format.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty configuration: GeomAIPredictionConfiguration\n\nThe configuration used to run the prediction.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed"},{"objectID":"API reference","href":"api_reference/geomai/predictions.html#configuration","title":"API reference > GeomAIPredictions > Configuration","text":"Configuration\n\n\n\npydantic model GeomAIPredictionConfiguration\n\nThe configuration used to run a GeomAI prediction.\n\nRaises InvalidArguments if the input data cannot be validated to from a valid model.\n\n\n\nfield latent_params: List[float] [Required]\n\nA list of floats that represent the position of the geometry in the latent space.\n\nThese parameters describe the shape in a compressed form.\nThe number of floats should match the nb_latent_param your model was requested with.\n\nRequired.\n\n\n\nfield resolution: Tuple[Annotated[int, Gt(gt=0)], Annotated[int, Gt(gt=0)], Annotated[int, Gt(gt=0)]] | None = None\n\nA list of three integers defining the number of voxels along the X, Y, and Z axes.\n\nUse higher resolution for complex or precise geometries, and lower resolution for simple shapes or quick previews.\n\nThe total number of voxels must not exceed 900^3, that is x, y, z multiplied together must be less than or equal to 900^3.\nIf you exceed that value, an error will occur.\n\nDefaults to [100,100,100], if None is provided.\n\nFor the maximum resolution of 900^3, the prediction takes approximately 10 minutes (approximately 1 microsecond per voxel)."},{"objectID":"User guide","href":"user_guide/configuration_guide/installation.html#installation","title":"User guide > Installation","text":"Installation\n\nPySimAI requires Python 3.9 or later.\n\nInstall PySimAI with this command:\n\nUse this same command every time you want to update PySimAI."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/sg_execution_times.html#computation-times","title":"Computation times","text":"Computation times\n\n00:00.000 total execution time for 3 files from _examples/00_basic_simai_ex:\n\n\n\n\n\n\n\nExample\n\nTime\n\nMem (MB)\n\nsphx_glr__examples_00_basic_simai_ex_00-create_project_upload_data.py (00-create_project_upload_data.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_00_basic_simai_ex_01-build_model.py (01-build_model.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_00_basic_simai_ex_02-run_predictions.py (02-run_predictions.py)\n\n00:00.000\n\n0.0"},{"objectID":"API reference","href":"api_reference/training_data.html#trainingdata","title":"API reference > TrainingData","text":"TrainingData\n\n\n\nA TrainingData instance is a\ncollection of TrainingDataPart\ninstances representing a simulation that can be used as input for the training of models.\n\nFor standard workflows, the upload_folder() feature is recommended\nas it simplifies the process and automatically handles data extraction."},{"objectID":"API reference","href":"api_reference/training_data.html#directory","title":"API reference > TrainingData > Directory","text":"Directory\n\n\n\nclass TrainingDataDirectory\n\nProvides a collection of methods related to training data.\n\nThis class is accessed through client.training_data.\n\nExample\n\nList all of the training data:\n\n\n\n\n\ncreate(name: str, project: Project | str | None = None) -> TrainingData\n\nCreate a TrainingData object.\n\nParameters\n\nname (str) – Name to give the new TrainingData object.\n\nproject (Project | str | None) – Project object to associate the data with.\n\nReturns\n\nCreated TrainingData object.\n\nReturn type\n\nTrainingData\n\n\n\ndelete(training_data: TrainingData | str) -> None\n\nDelete a TrainingData object and its associated parts from the server.\n\nParameters\n\ntraining_data (TrainingData | str) – ID or model object of the TrainingData object.\n\n\n\nget(id: str | None = None, name: str | None = None) -> TrainingData\n\nGet a specific TrainingData object from the server.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the training data.\n\nname (str | None) – Name of the training data.\n\nRaises\n\nansys.simai.core.errors.NotFoundError – If the training data doesn’t exist\n\n\n\niter(filters: dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], Any]] | list[RawSingleFilter] | None = None) -> SizedIterator[TrainingData]\n\nIterate over all TrainingData objects on the server.\n\nParameters\n\nfilters (dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], ~typing.Any]] | list[~ansys.simai.core.data.types.RawSingleFilter] | None) – Optional Filters to apply.\n\nReturns\n\nIterator over all TrainingData objects on the server.\n\nReturn type\n\nSizedIterator[TrainingData]\n\n\n\nlist(filters: dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], Any]] | list[RawSingleFilter] | None = None) -> List[TrainingData]\n\nList all TrainingData objects on the server.\n\nThis can take a very long time, consider using iter() instead.\n\nParameters\n\nfilters (dict[str, Any] | list[tuple[str, Literal['EQ', 'LIKE', 'IN', 'GT', 'GTE', 'LT', 'LTE'], ~typing.Any]] | list[~ansys.simai.core.data.types.RawSingleFilter] | None) – Optional Filters to apply.\n\nReturns\n\nList of all TrainingData objects on the server.\n\nReturn type\n\nList[TrainingData]\n\n\n\nupload_folder(training_data: TrainingData | str, folder_path: Path | str | PathLike) -> List[TrainingDataPart]\n\nUpload all files in a folder to a TrainingData object.\n\nThis method automatically requests computation of the training data once the upload is complete\nunless specified otherwise.\n\nParameters\n\ntraining_data (TrainingData | str) – ID or model object of the training data to upload parts to.\n\nfolder_path (Path | str | PathLike) – Path to the folder that contains the files to upload.\n\n\n\nupload_part(training_data: TrainingData | str, file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], monitor_callback: Callable[[int], None] | None) -> TrainingDataPart\n\nAdd a part to a TrainingData object.\nUse TrainingData.extract_data() after all parts are uploaded (to convert the status of data to Ready for model).\n\nParameters\n\ntraining_data (TrainingData | str) – ID or model object of the training data to\nadd the part to.\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the upload.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nAdded TrainingDataPart object.\n\nReturn type\n\nTrainingDataPart"},{"objectID":"API reference","href":"api_reference/training_data.html#model","title":"API reference > TrainingData > Model","text":"Model\n\n\n\nclass TrainingData\n\nProvides the local representation of a training data object.\n\n\n\n\n\nadd_to_project(project: Project | str)\n\nAdd the training data to a Project object.\n\nParameters\n\nproject (Project | str) – ID or model object of the project to add the data to.\n\n\n\nassign_subset(project: Project | str, subset: SubsetEnum | str | None) -> None\n\nAssign the training data to a subset in relation to a given project.\n\nParameters\n\nproject (Project | str) – ID or model\n\nsubset (SubsetEnum | str | None) – SubsetEnum attribute (e.g. SubsetEnum.TRAINING) or string value (e.g. “Training”) or None to unassign.\nAvailable options: (Training, Test)Each new training data added to the project will be set to “None” by default.None allows for resetting the subset assignment of your training data, which will be automatically allocated\nin either test or training subsets upon each model building request. As a rule of thumb, 10% of all data should\nbe allocated to the test subset.When wanting to assign a specific subset to your training data, note that:Each subset requires at least one data point.\nThe training subset is used to train the model. The test subset is used for the model\nevaluation report but is not learned by the model.\nIt is recommended to allocate about 10% of your data to the test subset.\n\nReturns\n\nNone\n\nReturn type\n\nNone\n\n\n\ndelete() -> None\n\nDelete the training data on the server.\n\n\n\n\n\nextract_data() -> None\n\nExtract or reextract the data from a training data.\n\nData should be extracted from a training data once all its parts have been fully uploaded.\nThis is done automatically when using TrainingDataDirectory.upload_folder() to create training data.\n\nData can only be reextracted from a training data if the extraction previously failed or if new files have been added.\n\n\n\n\n\nget_subset(project: Project | str) -> SubsetEnum | None\n\nGet the subset that the training data belongs to, in relation to the given project.\n\nParameters\n\nproject (Project | str) – ID or model of the project to check\nthe Project object for, or its ID.\n\nReturns\n\nThe SubsetEnum of the subset to which\nthe TrainingData belongs to if any, None otherwise.\n(e.g. <SubsetEnum.TEST: ‘Test’>)\n\nReturn type\n\nSubsetEnum | None\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nremove_from_project(project: Project | str)\n\nRemove the training data from a Project object.\n\nParameters\n\nproject (Project | str) – ID or model of the project to remove data from.\n\nRaises\n\nansys.simai.core.errors.ApiClientError – If the data is the project’s sample.\n\nansys.simai.core.errors.ApiClientError – If the project is in training.\n\n\n\nrename(new_name: str) -> None\n\nChange the name of the training data.\n\nParameters\n\nnew_name (str) – New name to give to the training data object.\n\n\n\nupload_folder(folder_path: Path | str | PathLike) -> List[TrainingDataPart]\n\nUpload all the parts contained in a folder to a TrainingData instance.\n\nUpon upload completion, SimAI will extract data from each part.\n\nParameters\n\nfolder_path (Path | str | PathLike) – Path to the folder with the files to upload.\n\nReturns\n\nList of uploaded training data parts.\n\nReturn type\n\nList[TrainingDataPart]\n\n\n\nupload_part(file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], monitor_callback: Callable[[int], None] | None = None) -> TrainingDataPart\n\nAdd a part to the training data.\n\nParameters\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nCreated TrainingDataPart.\n\nReturn type\n\nTrainingDataPart\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty extracted_metadata: Dict | None\n\nMetadata extracted from the training data.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty name: str\n\nName of the training data.\n\n\n\nproperty parts: List[TrainingDataPart]\n\nList of all parts\nobjects in the training data."},{"objectID":"API reference","href":"api_reference/models.html#models","title":"API reference > Models","text":"Models\n\n\n\n\n\nA collection of classes for building a SimAI model.\nLaunching a build requires a configuration\n(ModelConfiguration)\nwhich defines the model properties, such as its inputs and outputs,\nthe Global Coefficients and the Domain of Analysis, and its project. The\nModelConfiguration\nobject is, then, parsed to models.build() for\nlaunching a build."},{"objectID":"API reference","href":"api_reference/models.html#directory","title":"API reference > Models > Directory","text":"Directory\n\n\n\nclass ModelDirectory\n\nProvides a collection of methods related to building models.\n\n\n\n\n\nbuild(configuration: ModelConfiguration, dismiss_data_with_fields_discrepancies: bool = False, dismiss_data_with_volume_overflow: bool = False, dismiss_data_input_with_nan: bool = False)\n\nLaunches a build given a configuration.\n\nParameters\n\nconfiguration (ModelConfiguration) – a ModelConfiguration object that contains the properties to be used in the build\n\ndismiss_data_with_fields_discrepancies (bool) – set to True for omitting data with missing properties\n\ndismiss_data_with_volume_overflow (bool) – set to True for omitting data outside the Domain of Analysis\n\ndismiss_data_input_with_nan (bool) – set to True for omitting data with inputs containing NaN values\n\nExample\n\nUse a previous configuration for a new build in the same project\n\nUse a previous configuration for a new build in another project"},{"objectID":"API reference","href":"api_reference/models.html#model","title":"API reference > Models > Model","text":"Model\n\n\n\nclass Model\n\nTraining model representation.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty configuration: ModelConfiguration\n\nBuild configuration of a model.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty project_id: str\n\nThe ID of the project where the model exists."},{"objectID":"User guide","href":"user_guide/generative_design_ug/best_practices.html#best-practices","title":"User guide > Best practices","text":"Best practices"},{"objectID":"User guide","href":"user_guide/generative_design_ug/best_practices.html#generative-design-with-ai","title":"User guide > Best practices > Generative design with AI","text":"Generative design with AI\n\nThe principle is that:\n\nGiven a dataset of geometries provided by the user,\n\nThe AI model is trained to find a compressed representation of those given geometries.\n\nOnce the representation is computed, the model can generate new geometries by working in this compressed representation space.\n\nThis principle is based on the AI concept of latent space."},{"objectID":"User guide","href":"user_guide/generative_design_ug/best_practices.html#concept-of-latent-space","title":"User guide > Best practices > Concept of latent space","text":"Concept of latent space\n\nThe latent space is a compressed version of complex data, converted into a representation that captures the most important features.\n\nTo generate a meaningful geometry from a latent space, it is effective to approximate its corresponding latent representation (namely, its code)\nby computing a weighted average of two codes from a code dictionary (that is, a collection of latent codes derived from the training data).\nThis approach leverages the smooth structure of the latent space, where intermediate points between known latent representations\ncan correspond to meaningful interpolations of their associated geometries."},{"objectID":"User guide","href":"user_guide/generative_design_ug/best_practices.html#training-data-requirements","title":"User guide > Best practices > Training data requirements","text":"Training data requirements\n\nThe geometries used as training data must comply with the following requirements to be correctly processed:\n\nInput file formats: .vtp or .stl.\n\nBe a watertight geometry.\n\nA geometry is watertight if it forms a completely closed surface with no holes or gaps. Each edge must be shared by exactly two faces.\n\nBe a manifold geometry.\n\nA geometry is manifold if every edge is connected to exactly two faces and each vertex has a well-defined, continuous neighborhood without branching or overlaps.\n\nNot Self-Penetrate.\n\nThe geometry must not intersect with itself. No part of the surface should pass through another part of the same object."},{"objectID":"Home","href":"_examples/sg_execution_times.html#computation-times","title":"Computation times","text":"Computation times\n\n00:00.000 total execution time for 0 files from _examples:\n\n\n\n\n\n\n\nExample\n\nTime\n\nMem (MB)\n\nN/A\n\nN/A\n\nN/A"},{"objectID":"Home","href":"_examples/02_generative_design_ex/index.html#generative-design","title":"Generative Design","text":"Generative Design\n\nThis section provides a collection of practical script examples illustrating the Generative Design feature of SimAI.\nThey serve as a reference guide for users to implement similar solutions in their projects.\n\nsphx_glr__examples_02_generative_design_ex_00-create_project_upload_data.py\n\nsphx_glr__examples_02_generative_design_ex_01-build_model.py\n\nsphx_glr__examples_02_generative_design_ex_02-generate_random_geometries.py\n\nsphx_glr__examples_02_generative_design_ex_03-interpolate_geometries.py\n\n"},{"objectID":"API reference","href":"api_reference/geometries.html#geometries","title":"API reference > Geometries","text":"Geometries\n\n\n\n\n\nGeometries are the core of SimAI deep learning-powered predictions.\nA geometry is a 3D model and the associated metadata managed by the SimAI platform.\n\n"},{"objectID":"API reference","href":"api_reference/geometries.html#file-format","title":"API reference > Geometries > File format","text":"File format\n\nThe input format for your workspace is described by the model manifest.\nYou use the workspace.model.geometry\nattribute to access the information for a specific workspace."},{"objectID":"API reference","href":"api_reference/geometries.html#directory","title":"API reference > Geometries > Directory","text":"Directory\n\n\n\nclass GeometryDirectory\n\nProvides a collection of methods related to geometries.\n\nThis class is accessed through client.geometries.\n\nExample\n\n\n\n\n\ndelete(geometry: Geometry | str) -> None\n\nDelete a specific geometry and its data from the server.\n\nAll the objects associated with this geometry (predictions and postprocessings)\nare also deleted.\n\nParameters\n\ngeometry (Geometry | str) – ID or model of the geometry.\n\nRaises\n\nNotFoundError – No geometry with the given ID exists.\n\nGeometry.delete()\n\n\n\ndownload(geometry: Geometry | str, file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None, monitor_callback: Callable[[int], None] | None = None) -> None | BinaryIO\n\nDownload the geometry with the given ID into the file at the given path.\n\nParameters\n\ngeometry (Geometry | str) – ID or model of the geometry.\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Optional binary file-object or the path of the file to put the\ncontent into.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nNone if a file is provided or a BytesIO object with the geometry’s content otherwise.\n\nReturn type\n\nNone | BinaryIO\n\nGeometry.download()\n\n\n\nfilter(**kwargs: Dict[str, str | float | Range]) -> List[Geometry]\n\nFilter geometries from the server that belong to the currently set workspace.\n\nParameters\n\nkwargs (Dict[str, str | float | Range]) – Filters to apply. Only the elements with matching key-values in\ntheir metadata are returned. Each filter can be one of the following data types:A string\n\nA numerical value (int or float)\n\nA Range condition for filtering values matching a\ngiven numerical range of values\n\nReturns\n\nList of filtered geometries on the server.\n\nRaises\n\nTypeError – If a Range condition is applied on non-numerical metadata.\n\nReturn type\n\nList[Geometry]\n\n\n\nget(name: str | None = None, id: str | None = None, workspace: Workspace | str | None = None) -> Geometry\n\nGet a specific geometry object from the server either by name or ID.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nname (str | None) – Name of the geometry.\n\nid (str | None) – ID of the geometry.\n\nworkspace (Workspace | str | None) – ID or model of the workspace containing the geometry.\nThis parameter is necessary if providing a name and no global workspace is set for the client.\n\nReturns\n\nGeometry.\n\nRaises\n\nInvalidArguments – If neither a name nor an ID is given.\n\nNotFoundError – If no geometry with the given name or ID exists.\n\nReturn type\n\nGeometry\n\nExamples\n\nGet a geometry by name.\n\nGet a geometry by ID.\n\n\n\nlist(workspace: Workspace | str | None = None, filters: Dict[str, str | float | Range] | None = None) -> List[Geometry]\n\nList geometries from the server that belong to the currently set workspace or the specified one.\n\nParameters\n\nworkspace (Workspace | str | None) – ID or model of the workspace to list geometries for.\nThis parameter is required if no global workspace is set for the client.\n\nfilters (Dict[str, str | float | Range] | None) – Optional filters. Only the elements with matching key-values in\ntheir metadata are returned. Each filter can be one of the following data types:A string\n\nA numerical value (int or float)\n\nA Range condition for filtering values matching a\ngiven numerical range of values\n\nReturns\n\nList of all or filtered geometries on the server.\n\nRaises\n\nTypeError – If a Range condition is applied on non-numerical metadata.\n\nReturn type\n\nList[Geometry]\n\n\n\nsweep(candidate_geometry: Geometry | str, swept_metadata: str | List[str] | None = None, fixed_metadata: List[str] | None = None, geometries: List[Geometry] | None = None, order: int | None = None, include_center: bool | None = None, include_diagonals: bool | None = None, tolerance: float | None = None) -> List[Geometry]\n\nGet the geometries whose metadata are closest to the candidate geometry.\n\nFor more information, see the Geometry.sweep() method.\n\nExample\n\nGeometry.sweep()\n\n\n\n\n\nupload(file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], metadata: Dict[str, Any] | None = None, workspace: Workspace | str | None = None, monitor_callback: Callable[[int], None] | None = None, **kwargs) -> Geometry\n\nUpload a geometry to the SimAI platform.\n\nParameters\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – Binary file-object or the path of the geometry to open.\nFor more information, see the NamedFile class.\n\nmetadata (Dict[str, Any] | None) – Optional metadata to add to the geometry’s simple key-value store.\nLists and nested objects are not supported.\n\nworkspace (Workspace | str | None) – ID or model of the workspace to\nupload the geometry to. This parameter is only necessary if no workspace\nis set for the client.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nCreated Geometry object.\n\nReturn type\n\nGeometry"},{"objectID":"API reference","href":"api_reference/geometries.html#model","title":"API reference > Geometries > Model","text":"Model\n\n\n\nclass Geometry\n\nProvides the local representation of a geometry object.\n\n\n\ndelete() -> None\n\nDelete the geometry and its data from the server.\n\nAll the objects associated with this geometry (predictions and postprocessings)\nare also deleted.\n\nGeometryDirectory.delete()\n\n\n\n\n\ndelete_point_cloud()\n\nDelete the associated point cloud file.\n\n\n\ndownload(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None, monitor_callback: Callable[[int], None] | None = None) -> None | BinaryIO\n\nDownload the geometry into the provided file or in memory if no file is provided.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Optional binary file-object or the path of the file to put the\ncontent into.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback to monitor the progress of the download.\nFor more information, see the MonitorCallback\nobject.\n\nReturns\n\nNone if a file is provided or the BytesIO object with the geometry’s content otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\nget_predictions() -> List[Prediction]\n\nGet the prediction objects associated with the geometry.\n\n\n\n\n\nlist_predictions() -> List[Prediction]\n\nLists all the predictions associated with the geometry.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nrename(new_name: str) -> None\n\nChange the name of the geometry.\n\nParameters\n\nnew_name (str) – New name to give to the geometry.\n\nOnly the stem part is modified. The file extension is immutable.\nIf a file extension is provided, it must be the same as the original one.\nIf the new filename already contains dots other than for the extension,\nthe extension must be provided.\n\n\n\nrun_prediction(scalars: Dict[str, Number] | None = None, boundary_conditions: Dict[str, Number] | None = None, **kwargs) -> Prediction\n\nRun a new prediction or return an existing prediction.\n\nThis is a non-blocking method. The prediction object is returned.\nThis object may be incomplete if its computation is not finished,\nin which case the information is filled once the computation is complete.\nThe state of the computation can be monitored with the prediction’s is_ready\nattribute or waited upon with its wait() method.\n\nTo learn more about the expected scalars in your workspace, you can use the\nsimai.current_workspace.model.scalars or simai.predictions.scalars,\nwhere ex is your ~ansys.simai.core.client.SimAIClient object.\n\nParameters\n\nscalars (Dict[str, Number] | None) – Scalars to apply as a dictionary.\n\nboundary_conditions (Dict[str, Number] | None) – (Deprecated) Boundary conditions to apply as a dictionary.\n\n**kwargs – Scalars to pass as keyword arguments.\n\nReturns\n\nCreated prediction object.\n\nRaises\n\nProcessingError – If the server failed to process the request.\n\nReturn type\n\nPrediction\n\nExamples\n\nUse kwargs:\n\n\n\nsweep(swept_metadata: str | List[str] | None = None, fixed_metadata: List[str] | None = None, geometries: List[Geometry] | None = None, order: int | None = None, include_center: bool | None = None, include_diagonals: bool | None = None, tolerance: float | None = None) -> List[Geometry]\n\nReturn geometries whose metadata are closest to the candidate geometry.\n\nThis method returns geometries that have the values closest to the candidate\ngeometry for each considered metadata variable. For example, if\nsweeping along length and width metadata variables, the method\nreturns geometries that have identical width and the closest smaller\nand larger length, as well as identical length and the closest smaller\nand larger width.\n\nThe fixed_metadata array allows you to fix one or several variables.\nFor each fixed variable, the resulting geometries must have\na metadata value equal to the considered geometry. For example, if\nfixed_metadata is [\"xbow\"], every geometry.metadata[\"xbow\"]\nresult must be equal to the candidate_geometry.metadata[\"xbow\"].\n\nMetadata passed neither in swept_metadata nor in fixed_metadata\nare ignored and can have any value (or absence thereof).\n\nParameters\n\nswept_metadata (str | List[str] | None) – Optional metadata name or a list of metadata names\nto consider. Only variables containing numerical values are\nsupported. If no metadata names are passed, all metadata containing\nnumerical values are taken into account.\n\nfixed_metadata (List[str] | None) – Optional list of metadata variables that should\nbe fixed, meaning that all the resulting geometries\nhave those values equal to the candidate geometry.\n\ngeometries (List[Geometry] | None) – Optional list of Geometry objects to consider for sweeping.\nIf no Geometry objects are passed, all geometries are used.\n\ntolerance (float | None) – Optional delta. If the difference between two numbers\nis lower than the tolerance, they are considered as equal.\nThe default is 10**-6.\n\norder (int | None) – Optional depth of the sweep. The default is 1. This parameter\ndetermines the number of returned groups of equal smaller and\nlarger values for each swept variable. For example, if sweeping\non a space with lengths [1, 2.1, 2.1, 3.5, 3.5, 4, 4]\nfrom the candidate with length=1, order=2 returns\nthe geometries with lengths 2.1, 2.1, 3.5, 3.5.\n\ninclude_center (bool | None) – Optional Boolean indicating whether geometries with values\nequal to the candidate geometry (including the candidate itself) are\nto be returned among the result. The default is False.\n\ninclude_diagonals (bool | None) – Optional Boolean indicating whether to include diagonals\nwhen sweeping on more than one variable. The default is False.\nFor example, if sweeping on two variables from point (0, 0)\nand with order=1, in addition to (0, 1) and (1, 0),\ngeometry (1, 1) is returned.\n\nReturns\n\nList of Geometry objects neighboring the candidate geometry for each metadata.\n\nRaises\n\nValueError – If a passed variable doesn’t exist in the\n    candidate geometry.\n\nValueError – If the considered metadata contains non-numerical values\n    or mixed numerical and non numerical values.\n\nReturn type\n\nList[Geometry]\n\nExample\n\n\n\nupdate_metadata(metadata: Dict[str, str | Number | bool])\n\nChange the metadata of the geometry.\n\nNew keys-values are added.\n\nExisting keys-values are overwritten.\n\nOther key-values are not changed.\n\nTo delete a metadata, set it to None explicitly.\n\nParameters\n\nmetadata (Dict[str, str | Number | bool]) – Dictionary with the new data.\n\nExamples\n\nAdd or update a metadata.\n\nRemove all metadata.\n\n\n\nupload_point_cloud(file: Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str], monitor_callback: Callable[[int], None] | None = None)\n\nUpload a point cloud for this geometry.\n\nOnly the vtp file format is supported\n\nParameters\n\nfile (Path | str | PathLike | Tuple[BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike, str]) – NamedFile to upload.\n\nmonitor_callback (Callable[[int], None] | None) – Optional callback for monitoring the progress of the upload.\nFor more information, see the MonitorCallback\nobject.\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty creation_time: str\n\nTime when the geometry was created in a UTC ISO8601 format string.\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nproperty metadata: Dict[str, Any]\n\nUser-given key-value associated with the geometry.\n\n\n\nproperty name: str\n\nName of the geometry.\n\n\n\nproperty point_cloud: Dict[str, Any] | None\n\nThe attached point cloud file information if any."},{"objectID":"API reference","href":"api_reference/geometries.html#filtering","title":"API reference > Geometries > Filtering","text":"Filtering\n\n\n\nclass Range\n\nDescribes a numerical range used for filtering geometries.\n\nRange objects describe a numerical range between a minimum and\na maximum boundary. Both are optional. Thus, if no maximum boundary\nis passed, the range describes values greater than or equal to the\nminimum boundary. Note that ranges are inclusive. Thus, both minimum\nand maximum boundaries match if they are equal to the passed value\n(as opposed to Python’s range() method).\n\nRanges can be used as a filter in the\ngeometries.list method.\n\nParameters\n\nmin (float | None) – Minimum boundary.\n\nmax (float | None) – Maximum boundary.\n\ntolerance (float | None) – Tolerance delta. Two values whose difference is smaller\nthan the tolerance are considered as equal."},{"objectID":"API reference","href":"api_reference/geomai/projects.html#geomaiprojects","title":"API reference > GeomAIProjects","text":"GeomAIProjects\n\n\n\nProjects are a selection of training data used to train a model."},{"objectID":"API reference","href":"api_reference/geomai/projects.html#directory","title":"API reference > GeomAIProjects > Directory","text":"Directory\n\n\n\nclass GeomAIProjectDirectory\n\nProvides a collection of methods related to projects.\n\nThis class is accessed through client.projects.\n\nExample\n\nList all projects:\n\n\n\n\n\ncancel_build(project: GeomAIProject | str)\n\nCancel a build if one is in progress.\n\nParameters\n\nproject (GeomAIProject | str) – ID or model of the project.\n\n\n\ncreate(name: str) -> GeomAIProject\n\nCreate a project.\n\n\n\n\n\ndelete(project: GeomAIProject | str) -> None\n\nDelete a project.\n\nParameters\n\nproject (GeomAIProject | str) – ID or model of the project.\n\n\n\nget(id: str | None = None, name: str | None = None) -> GeomAIProject\n\nGet a project by either ID or name.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the project.\n\nname (str | None) – Name of the project.\n\nReturns\n\nGeomAIProject instance with the given ID if it exists.\n\nRaises\n\nNotFoundError – If the project doesn’t exist\n\nReturn type\n\nGeomAIProject\n\n\n\nlist() -> List[GeomAIProject]\n\nList all projects available on the server.\n\n"},{"objectID":"API reference","href":"api_reference/geomai/projects.html#model","title":"API reference > GeomAIProjects > Model","text":"Model\n\n\n\nclass GeomAIProject\n\nProvides the local representation of a GeomAI project object.\n\n\n\n\n\nbuild_model(configuration: dict | GeomAIModelConfiguration) -> GeomAIModel\n\nLaunches a GeomAI build with the given configuration.\n\nParameters\n\nconfiguration (dict | GeomAIModelConfiguration) – the configuration to run the model with.\nSee models.GeomAIModelConfiguration for details.\n\n\n\ncancel_build()\n\nCancels a build if there is one pending.\n\nRaises\n\nProcessingError – If there is no build to cancel\n\n\n\ncreate_workspace(name: str) -> GeomAIWorkspace\n\nCreates a workspace using the latest model trained in this project.\n\nParameters\n\nname (str) – Name to give to the new workspace\n\n\n\ndata() -> List[GeomAITrainingData]\n\n(Deprecated) Lists all GeomAITrainingData instances in the project.\n\nUse list_training_data() instead.\n\n\n\n\n\ndelete() -> None\n\nDelete the project.\n\n\n\n\n\nlist_models() -> List[GeomAIModel]\n\nLists all GeomAIModel instances in the project.\n\n\n\n\n\nlist_training_data() -> List[GeomAITrainingData]\n\nLists all GeomAITrainingData instances in the project.\n\n\n\n\n\nlist_workspaces() -> List[GeomAIWorkspace]\n\nLists all GeomAIWorkspace instances in the project.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nrename(new_name: str) -> None\n\nRename the project.\n\nParameters\n\nnew_name (str) – New name to give to the project.\n\n\n\nset_as_current_project() -> None\n\nConfigure the client to use this project instead of the one currently configured.\n\n\n\n\n\nworkspaces() -> List[GeomAIWorkspace]\n\n(Deprecated) Lists all GeomAIWorkspace instances in the project.\n\nUse list_workspaces() instead.\n\n\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty last_model_configuration: GeomAIModelConfiguration | None\n\nLast configuration used for model training in this project.\n\n\n\nproperty name: str\n\nName of project."},{"objectID":"Home","href":"_examples/01_pysimai_ex/02-subset_assignment.html#subset-assignment","title":"Subset assignment","text":"Subset assignment\n\nThis example demonstrates how to assign a subset\nto a training data."},{"objectID":"Home","href":"_examples/01_pysimai_ex/02-subset_assignment.html#import-necessary-libraries","title":"Subset assignment > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/01_pysimai_ex/02-subset_assignment.html#select-a-training-data","title":"Subset assignment > Select a training data","text":"Select a training data\n\nExample of a training_data_id associated with a project_id."},{"objectID":"Home","href":"_examples/01_pysimai_ex/02-subset_assignment.html#get-subset-assignment","title":"Subset assignment > Get subset assignment","text":"Get subset assignment\n\nGet and print the current subset assigned for this training_data_id."},{"objectID":"Home","href":"_examples/01_pysimai_ex/02-subset_assignment.html#assign-a-new-subset-two-options","title":"Subset assignment > Assign a new subset (two options)","text":"Assign a new subset (two options)\n\nManually assign a new subset to the training data.\n\nAlternatively, use SubsetEnum to assign a valid enum value to the training data.\n\n\n\nDownload Jupyter notebook: 02-subset_assignment.ipynb\n\nDownload Python source code: 02-subset_assignment.py\n\nDownload zipped: 02-subset_assignment.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"Home","href":"index.html#pysimai-documentation","title":"PySimAI documentation","text":"PySimAI documentation\n\nRelease v0.3.10 (Changelog)\n\nPySimAI is part of the PyAnsys ecosystem that allows you to use SimAI within\na Python environment of your choice in conjunction with other PyAnsys libraries and external Python\nlibraries. With PySimAI, you can manage and access your data on the platform from within Python apps and\nscripts.\n\nThe following illustration depicts the Ansys SimAI platform and PySimAI library user workflow.\n\nFor more information, see the Ansys SimAI User’s guide\n\n User guide\n\nGuides on how to achieve specific tasks with PySimAI.\n\nref_user_guide\n\n API reference\n\nDescribes the public Python classes, methods, and functions.\n\napi_reference\n\n Examples\n\nA collection of examples demonstrating the capabilities of PySimAI.\n\n_examples/index"},{"objectID":"Home","href":"index.html#requirements","title":"PySimAI documentation > Requirements","text":"Requirements\n\nPySimAI requires Python 3.9 or later.\n\n"},{"objectID":"User guide","href":"user_guide/generative_design_ug/model_config_and_training.html#model-configuration-and-training","title":"User guide > Model configuration and training","text":"Model configuration and training\n\nLearn about the parameters to set when configuring and training your AI model."},{"objectID":"User guide","href":"user_guide/generative_design_ug/model_config_and_training.html#build-presets","title":"User guide > Model configuration and training > Build presets","text":"Build presets\n\nUse the build_preset parameter to configure the training duration for building your model.\n\nDurations available are:\n\ndebug: 4 minutes + 15 sec per geometry.\n\nshort: 45 minutes + 15 sec per geometry.\n\ndefault: 3 hours + 15 sec per geometry.\n\nlong: 15 hours + 15 sec per geometry.\n\nTo select the right build preset, consider the size of the training dataset and the complexity of the geometries.\nIn this context, the number of polygons in a mesh is a rough estimate of the complexity of the geometry it represents:\nsimple geometries can be modeled with few polygons, while complex ones need more polygons.\n\nFor small datasets with simple geometries (low polygon count), use short preset.\n\nFor large datasets or geometries with high polygon count, use longer presets (default or long)."},{"objectID":"User guide","href":"user_guide/generative_design_ug/model_config_and_training.html#number-of-epochs","title":"User guide > Model configuration and training > Number of epochs","text":"Number of epochs\n\nYou can also configure the number of training iterations for building your model through the nb_epochs parameter.\nnb_epochs corresponds to the number of times each training data is seen by the model during the training, between 1 and 1000.\n\nnb_epochs should only be used by expert users.\nWhile it enables finer customization, it requires prior knowledge on the model’s performance.\nA good approach is to start with build_preset and switch to nb_epochs when further customization is needed."},{"objectID":"User guide","href":"user_guide/generative_design_ug/model_config_and_training.html#number-of-latent-parameters","title":"User guide > Model configuration and training > Number of latent parameters","text":"Number of latent parameters\n\nThe number of latent parameters (nb_latent_param) defines the dimension of the latent space.\nIt also determines the length of the code, where the code is a set of parameters that represents the geometry within the latent space.\n\nUnless your use case has specific constraints with respect to the latent dimension, it is strongly recommended to rely on the default value (512).\n\nIncreasing the number of latent parameters allows the model to encode more complex variations and fine geometric details,\nimproving its ability to fit the training data. However, this also raises the risk of overfitting,\nwhere the model memorizes the training geometries instead of learning general patterns.\nOverfitting can lead to poor performance on new, unseen geometries.\n\nIf the number of latent parameters is too small, the model may underfit, failing to capture the necessary complexity of the data."},{"objectID":"Changelog","href":"changelog.html#changelog","title":"Changelog","text":"Changelog"},{"objectID":"Changelog","href":"changelog.html#0310-2026-02-19","title":"Changelog > 0.3.10 (2026-02-19)","text":"0.3.10 (2026-02-19)\n\nNew:\n\nEnable the use of output scalars in global coefficient formula.\n\nAdded support for generating, managing, and logging in with offline tokens via the current user object SimAIClient.me.\n\nAdd new set of methods to access lists of objects for Workspace, Project, Geometry and GeomAIProject\n\nChanges:\n\nRemove deprecated margin field in GeomAIPredictionConfiguration.\n\nUpdate the documentation for best practice with get_latent_parameters."},{"objectID":"Changelog","href":"changelog.html#039-2026-01-21","title":"Changelog > 0.3.9 (2026-01-21)","text":"0.3.9 (2026-01-21)\n\nChanges:\n\nUpdate the documentation related to nb_latent_param field in GeomAIModelConfiguration."},{"objectID":"Changelog","href":"changelog.html#038-2026-01-16","title":"Changelog > 0.3.8 (2026-01-16)","text":"0.3.8 (2026-01-16)\n\nNew:\n\nMake the nb_latent_param field in GeomAIModelConfiguration optional, and update its default and maximum value.\n\nAdded rename method for training data.\n\nFixes:\n\nReplace truthy fallback with explicit None check."},{"objectID":"Changelog","href":"changelog.html#037-2025-12-17","title":"Changelog > 0.3.7 (2025-12-17)","text":"0.3.7 (2025-12-17)\n\nNew:\n\nAdd basic SimAI examples in documentation.\n\nAdd method GeomAIWorkspace.get_latent_parameters() to retrieve latent parameters as dict in GeomAIWorkspace.\n\nRemove deprecated Optimization.run_parametric() optimization method.\n\nAdd model_configuration property in Workspace and GeomAIWorkspace.\n\nAllow users to use scalars in model output in model configuration and add a new post-processing PredictScalars.\n\nChanges:\n\nIncrease default timeout for long operations.\n\nDeprecate boundary_conditions in favor of scalars."},{"objectID":"Changelog","href":"changelog.html#036-2025-12-03","title":"Changelog > 0.3.6 (2025-12-03)","text":"0.3.6 (2025-12-03)\n\nNew:\n\nAdd renaming methods for Workspace, Project, Geometry, GeomAIWorkspace and GeomAIProject.\n\nAllow users to retrieve training data by name.\n\nAdd GeomAI examples in documentation.\n\nChanges:\n\nbuild_on_top parameter is deprecated in ModelConfiguration.\n\nmargin parameter is deprecated in GeomAIPredictionConfiguration.\n\nDocumentation improvements\n\nFixes:\n\nFix post-processing inputs in model configuration not being included in global coefficients processing.\n\nFix incorrect handling of dictionaries when building a GeomAI model."},{"objectID":"Changelog","href":"changelog.html#035-2025-10-14","title":"Changelog > 0.3.5 (2025-10-14)","text":"0.3.5 (2025-10-14)\n\nNew:\n\nAdd GeomAI model evaluation report download capabilities\n\nAdd support for point data in calculette and model training\n\nChanges:\n\nReplace requests/niquests with httpx\n\nDocumentation improvements\n\nRefactor the authentication logic\n\nFixes:\n\nFix GeomAI prediction deletion"},{"objectID":"Changelog","href":"changelog.html#034-2025-09-24","title":"Changelog > 0.3.4 (2025-09-24)","text":"0.3.4 (2025-09-24)\n\nNew:\n\nAdd axial_symmetry parameter to non-parametric optimization\n\nChanges:\n\nNon-parametric optimization now returns OptimizationResult\n\nSwitch to Niquest built-in SSE support\n\nRe-order non-parametric optimization parameters\n\nImprove error message when creating client with wrong organization\n\nDocumentation improvements\n\nFixes:\n\nFix improper exception handling\n\nFix unhandled SSE error"},{"objectID":"Changelog","href":"changelog.html#033-2025-07-02","title":"Changelog > 0.3.3 (2025-07-02)","text":"0.3.3 (2025-07-02)\n\nFixes:\n\nReplace verify_gc_formula with process_gc_formula."},{"objectID":"Changelog","href":"changelog.html#032-2025-07-02","title":"Changelog > 0.3.2 (2025-07-02)","text":"0.3.2 (2025-07-02)\n\nChanges:\n\nGeneral GeomAI improvements, including docs"},{"objectID":"Changelog","href":"changelog.html#031-2025-06-24","title":"Changelog > 0.3.1 (2025-06-24)","text":"0.3.1 (2025-06-24)\n\nNew:\n\nAdd max_displacement parameter to non-parametric optimization\n\nChanges:\n\nAdd checks on build on top\n\nBoundary conditions are optional on optimization runs\n\nUse new way to process global coefficients formula that uses a cache\n\nImproved checks for parametric and non parametric optimizations\n\nSwitch to uv\n\nDocs improvements"},{"objectID":"Changelog","href":"changelog.html#030-2025-05-14","title":"Changelog > 0.3.0 (2025-05-14)","text":"0.3.0 (2025-05-14)\n\nNew:\n\nRetry sending requests on HTTP 5xx error (#135)\n\nChanges:\n\nInclude python version in user_agent (#143)\n\nSSE: Don’t expect record from jobs with pending status (#141)"},{"objectID":"Changelog","href":"changelog.html#027-2025-03-26","title":"Changelog > 0.2.7 (2025-03-26)","text":"0.2.7 (2025-03-26)\n\nNew:\n\nAdd TrainingDataDirectory.iter as a more efficient alternative to listing training data.\n\nFixes:\n\nStop using deprecated endpoints\n\nDeleting PointCloud now cleanses the CustomVolumePointCloud post-processing cache"},{"objectID":"Changelog","href":"changelog.html#026-2025-01-23","title":"Changelog > 0.2.6 (2025-01-23)","text":"0.2.6 (2025-01-23)\n\nNew:\n\nAdd options for using custom TLS CA bundles in ClientConfig\n\nCheck if Project is trainable before build\n\nReintroduce surface evolution post-processing as SurfaceEvolution\n\nRaise an error when a variable is not found in the reference sample\n\nSupport post processing predict as learnt and predict on cells for surface variables by introducing SurfaceVTPTDLocation, together with the methods PredictionPostProcessings.surface_vtp_td_location() and SelectionPostProcessingsMethods.surface_vtp_td_location()\n\nChanges:\n\nRemove ModelManifest.version property from ModelManifest\n\nFixes:\n\nType hints on SimAIClient off by one\n\nFix pysimai version check"},{"objectID":"Changelog","href":"changelog.html#025-2024-11-05","title":"Changelog > 0.2.5 (2024-11-05)","text":"0.2.5 (2024-11-05)\n\nNew:\n\nAllow users to cancel build with Project.cancel_build()\n\nFilter training data in simai.training_data.list()\n\nAdded experimental Optimization.run_non_parametric()\n\nAdded an example section to the documentation\n\nChanges:\n\nOptimization.run() is now Optimization.run_parametric() and checks that the generation function has a suitable signature\n\nRemove deprecated design of experiments feature\n\nResolution steps are now printed upon error if any\n\nFixes:\n\nCorrect payload for surface post-processing inputs on model build"},{"objectID":"Changelog","href":"changelog.html#024-2024-09-23","title":"Changelog > 0.2.4 (2024-09-23)","text":"0.2.4 (2024-09-23)\n\nNew:\n\nAuth tokens are now cached in file system and get re-authenticated in a parallel fashion.\n\nInvalid refresh token now triggers a reauth instead of crashing.\n\nbuild_preset option in ModelConfiguration can now be one of debug, 1_day, 2_days, 7_days.\n\nModel Evaluation Report data (csv file) can now be downloaded with download_mer_data.\n\nTyping improvements; introducing JSON type is introduced and APIResponse type is updated to include JSON type.\n\nNew property Prediction.raw_confidence_score is added to Prediction, which returns the raw confidence score.\n\nFix:\n\nFixed the error where data was not in coordinance with the BE response. data now runs without errors."},{"objectID":"Changelog","href":"changelog.html#023-2024-08-21","title":"Changelog > 0.2.3 (2024-08-21)","text":"0.2.3 (2024-08-21)\n\nNew:\n\nAdded PostProcessInput class to define post processing input fields.\n\nAdded support for NaN and Inf for Global Coefficients and Post Processings.\n\nFixes:\n\nRemoved compute argument from TrainingData.upload_folder()\n\nFixed Model Configuration to raise a ProcessingError when volume field is missing from a sample specifying volume output.\n\nRemoved wakepy error mode success (deprecated) during optimization.\n\nRenamed TrainingData method compute() to TrainingData.extract_data().\n\nUpdated documentation of GeometryDirectory.upload(): the workspace_id argument was moved to workspace but never updated."},{"objectID":"Changelog","href":"changelog.html#022-2024-07-17","title":"Changelog > 0.2.2 (2024-07-17)","text":"0.2.2 (2024-07-17)\n\nNew:\n\nAdded support for the postprocessing of custom volume of point cloud. Use Geometry.upload_point_cloud to upload a point cloud file on a geometry and run the post processing through Prediction.post.custom_volume_point_cloud to run the postprocessing.\n\nFix:\n\nRemove internal uses of deprecated workspace.model"},{"objectID":"Changelog","href":"changelog.html#021-2024-06-28","title":"Changelog > 0.2.1 (2024-06-28)","text":"0.2.1 (2024-06-28)\n\nFixes:\n\nFixed bug that was crashing method ModelConfiguration.compute_global_coefficient(). The result of the Global Coefficient formula can now be retrieved."},{"objectID":"Changelog","href":"changelog.html#020-2024-06-28","title":"Changelog > 0.2.0 (2024-06-28)","text":"0.2.0 (2024-06-28)\n\nNew:\n\nModel configuration can now be created from scratch and be used in training requests.\n\nTraining-data subsets can now be assigned to None. Options Ignored and Validation are retired.\n\nFixes:\n\nFixed bug when uploading large files. Large files can now be uploaded.\n\nFixed bug when listing prediction without current_workspace being set."},{"objectID":"Changelog","href":"changelog.html#017-2024-04-30","title":"Changelog > 0.1.7 (2024-04-30)","text":"0.1.7 (2024-04-30)\n\nNew:\n\nAdded DomainOfAnalysis class to\nhelp set the domain of analysis on a new model.\n\nAdd workspace option where we previously relied only on the global workspace\n\nAdd prediction.post.list()\n\nFixes:\n\nReestablish python 3.9 compatibility.\n\nBump wakepy lib to fix errors when not able to prevent sleep during optimization."},{"objectID":"Changelog","href":"changelog.html#016-2024-04-25","title":"Changelog > 0.1.6 (2024-04-25)","text":"0.1.6 (2024-04-25)\n\nNew:\n\nAdded new method TrainingData.assign_subset() that allows you to assign a Train, Validation, or Test subset to your data.\n\nFixes:\n\nThe method Optimization.run()<ansys.simai.core.data.optimizations.OptimizationDirectory.run> now raises an exception if no workspace is provided and none is configured.\n\nFix RecursionError on authentication refresh"},{"objectID":"Changelog","href":"changelog.html#015-2024-04-15","title":"Changelog > 0.1.5 (2024-04-15)","text":"0.1.5 (2024-04-15)\n\nTraining can now be launched using the most recent model configuration from a project.\n\nEnabled non-interactive mode capability, allowing for automation or operations without manual inputs.\n\nAdded new validation Project.is_trainable() to verify if the project meets all minimum requirements for training.\n\nAdded new method Project.get_variables() to get all available variables used for a model’s inputs and outputs.\n\nFixed bug where a subset of training data could not be pulled. A subset of training data is now correctly retrieved.\n\nFixed erroneous call to a private function during the optimization run."},{"objectID":"Changelog","href":"changelog.html#014-2024-02-26","title":"Changelog > 0.1.4 (2024-02-26)","text":"0.1.4 (2024-02-26)\n\nLess verbose sse disconnects\n\nFix client config vars being described two times\n\nFix type/KeyError in workspace.model.post_processings\n\nFix monitor_callback interface not respected in upload_file_with_presigned_post\n\nFix README indentation"},{"objectID":"Changelog","href":"changelog.html#013-2024-02-02","title":"Changelog > 0.1.3 (2024-02-02)","text":"0.1.3 (2024-02-02)\n\nFix config args not taken into account if a config file is not found"},{"objectID":"Changelog","href":"changelog.html#012-2024-01-24","title":"Changelog > 0.1.2 (2024-01-24)","text":"0.1.2 (2024-01-24)\n\nFix training data upload_folder method"},{"objectID":"Changelog","href":"changelog.html#011-2024-01-19","title":"Changelog > 0.1.1 (2024-01-19)","text":"0.1.1 (2024-01-19)\n\nFix badges"},{"objectID":"Changelog","href":"changelog.html#010-2024-01-19","title":"Changelog > 0.1.0 (2024-01-19)","text":"0.1.0 (2024-01-19)\n\nInitial release"},{"objectID":"User guide","href":"user_guide/pysimai_ug/building_a_model.html#building-a-model","title":"User guide > Building a model","text":"Building a model\n\n\n\nBuilding a model with PySimAI is still experimental and subject to API changes.\n\nRebuilding a model using the last configuration of a project is supported for models created\nafter v0.1.5 (April 15, 2024).\n\nSimAI allows you to build AI models using past simulation data. This first step to building such models is to upload\nyour simulation data into a global pool of training data instances.\nThen, you assign the imported data to different Project instances,\nwhich you will eventually configure in order to build your AI model."},{"objectID":"User guide","href":"user_guide/pysimai_ug/building_a_model.html#create-a-project-and-upload-data","title":"User guide > Building a model > Create a project and upload data","text":"Create a project and upload data\n\nCreate a SimAIClient instance:\n\nYou are prompted for your credentials.\n\nIf desired, you can create an instance using a configuration file. For more\ninformation, see configuration.\n\nCreate a\nTrainingData instance\nand upload your simulation data into it:\n\nCreate a project:\n\nAssociate the created training data with the created project:\n\nYour project is created and your simulation data is associated with it. You can now configure and build your AI model."},{"objectID":"User guide","href":"user_guide/pysimai_ug/building_a_model.html#configure-and-build-the-model","title":"User guide > Building a model > Configure and build the model","text":"Configure and build the model\n\nImport the modules related to model building:\n\nSet the inputs (ModelInput) and outputs (ModelOutput) of the model:\n\nSet the Global Coefficients:\n\nSet the Domain of Analysis of the model using the DomainOfAnalysis instance:\n\nConfigure the model using the ModelConfiguration instance:\n\nVerify if the project meets the requirements for training and launch a build:\n\nYour AI model is configured and building."},{"objectID":"User guide","href":"user_guide/pysimai_ug/building_a_model.html#learn-more","title":"User guide > Building a model > Learn more","text":"Learn more\n\nFor more information on the actions available to you, see training_data,\ntraining_data_parts, projects, model_configuration, and models"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/index.html#simai-basics","title":"SimAI basics","text":"SimAI basics\n\nThis section provides a collection of practical script examples illustrating the basic SimAI workflow.\nThey serve as a step-by-step guide for users to get started with SimAI.\n\nsphx_glr__examples_00_basic_simai_ex_00-create_project_upload_data.py\n\nsphx_glr__examples_00_basic_simai_ex_01-build_model.py\n\nsphx_glr__examples_00_basic_simai_ex_02-run_predictions.py\n\n"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#building-a-generative-design-model","title":"Building a Generative Design Model","text":"Building a Generative Design Model\n\nThis example demonstrates how to configure a Generative Design model, start the model training process, and monitor the build progress."},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#before-you-begin","title":"Building a Generative Design Model > Before you begin","text":"Before you begin\n\nComplete “ref_create_project_upload_data” to create a project with training data.\n\nEnsure all training data in your project are ready (processed successfully)."},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#import-necessary-libraries","title":"Building a Generative Design Model > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#configure-your-settings","title":"Building a Generative Design Model > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:\n\nThe BUILD_PRESET options correspond to:\n\n\"debug\": Fast training for testing (very few epochs).\n\n\"short\": Quick training with reduced accuracy.\n\n\"default\": Balanced training time and quality.\n\n\"long\": Longer training for best quality."},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#initialize-the-client-and-get-the-project","title":"Building a Generative Design Model > Initialize the client and get the project","text":"Initialize the client and get the project\n\nConnect to the instance:\n\nRetrieve the project by name:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#verify-project-data-are-ready","title":"Building a Generative Design Model > Verify project data are ready","text":"Verify project data are ready\n\nBefore building a model, ensure all training data are processed:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#configure-the-model","title":"Building a Generative Design Model > Configure the model","text":"Configure the model\n\nTo define the configuration for your model, you can either specify the build preset or the number\nof epochs.\nTo do so, instead of build_preset, you can specify the number of epochs directly. Example: nb_epochs=100.\n\nThe number of latent parameters defines the complexity of the model’s latent space; start with a small number (e.g., 10) and adjust based on your needs."},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#build-the-model","title":"Building a Generative Design Model > Build the model","text":"Build the model\n\nStart the model training process:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#wait-for-model-training-to-complete","title":"Building a Generative Design Model > Wait for model training to complete","text":"Wait for model training to complete\n\nMonitor the training process and handle completion:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/01-build_model.html#next-steps","title":"Building a Generative Design Model > Next steps","text":"Next steps\n\nOnce your model is trained, you can:\n\nGenerate random geometries: ref_generate_random_geometries\n\nInterpolate between geometries: ref_interpolate_geometries\n\n\n\nDownload Jupyter notebook: 01-build_model.ipynb\n\nDownload Python source code: 01-build_model.py\n\nDownload zipped: 01-build_model.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"User guide","href":"user_guide/configuration_guide/proxy.html#working-behind-a-proxy","title":"User guide > Working behind a proxy","text":"Working behind a proxy\n\nBy default, the SimAI client attempts to get your proxy configuration, if any, from your system."},{"objectID":"User guide","href":"user_guide/configuration_guide/proxy.html#simai-client-configuration","title":"User guide > Working behind a proxy > SimAI client configuration","text":"SimAI client configuration\n\nYou can manually set a proxy when creating the SimAIClient\ninstance:\n\nAlternatively, you can store the proxy information in your configuration file.\n\nSetting this parameter overrides the default configuration retrieved from your system."},{"objectID":"User guide","href":"user_guide/configuration_guide/proxy.html#troubleshooting","title":"User guide > Working behind a proxy > Troubleshooting","text":"Troubleshooting\n\nIf you get an error of the type ProxyError([...], SSLCertVerificationError([...],\nit is likely that your proxy setup looks like |computer|<-https->|proxy|<-https->|internet|.\nBecause your web browser uses a special\nproxy auto-configuration file, the\nproxy is not trusted by your computer.\n\nThere are multiple ways to fix this issue:\n\nTry tls_ca_bundle=\"system\" (requires python>=3.10, see configuration).\n\nExtract the required CA certificate:\n\nExtract the certificates used by your company-configured browser on https://simai.ansys.com.\n\nSet tls_ca_bundle (or the REQUESTS_CA_BUNDLE environment variable):\n\nAs a temporary last resort, one can use tls_ca_bundle=\"unsecure-none\" (contact your IT department)."},{"objectID":"API reference","href":"api_reference/errors.html#errors","title":"API reference > Errors","text":"Errors\n\n\n\n\n\nexception ApiClientError(message: str, response: Response | None = None, request: Request | None = None)\n\nHTTP error from the SimAI API.\n\n\n\n\n\nexception ConfigurationError\n\nClient could not be configured properly.\n\n\n\nexception ConfigurationNotFoundError\n\nConfiguration file does not exist.\n\n\n\nexception ConnectionError(message: str, *, request: Request | None = None)\n\nCould not communicate with the server.\n\n\n\n\n\nexception InvalidArguments\n\nInvalid arguments were provided.\n\n\n\nexception InvalidClientStateError\n\nClient’s state is invalid.\n\n\n\nexception InvalidConfigurationError\n\nGiven configuration is not valid.\n\n\n\nexception InvalidOperationError\n\nThis operation is not possible in the current state.\n\n\n\nexception InvalidServerStateError\n\nServer’s state is invalid.\n\n\n\nexception MultipleErrors(exceptions: List[SimAIError])\n\nMultiple errors occurred.\n\n\n\n\n\nexception NotFoundError(message: str, response: Response | None = None, request: Request | None = None)\n\nRequired resource was not found on the server.\n\n\n\n\n\nexception ProcessingError\n\nData could not be processed.\n\n\n\nexception SimAIError\n\nProvides the base exception for all errors of the SimAI client.\n\nTo catch any expected error that the client might throw, use this exception."},{"objectID":"API reference","href":"api_reference/workspaces.html#workspaces","title":"API reference > Workspaces","text":"Workspaces\n\n\n\n\n\nWorkspaces are a set of specific geometries, predictions, and postprocessings.\nEach workspace uses a specific kernel.\n\nYou use the SimAIClient.set_current_workspace()\nmethod to set the workspace that the client is configured for."},{"objectID":"API reference","href":"api_reference/workspaces.html#directory","title":"API reference > Workspaces > Directory","text":"Directory\n\n\n\nclass WorkspaceDirectory\n\nProvides a collection of methods related to workspaces.\n\nThis class is accessed through client._workspaces.\n\nExample\n\n\n\n\n\ncreate(name: str, model_id: str) -> Workspace\n\nCreate a workspace.\n\nParameters\n\nname (str) – Name to give the new workspace.\n\nmodel_id (str) – ID of the model for the workspace to use.\n\n\n\ndelete(workspace: Workspace | str) -> None\n\nDelete a workspace.\n\nParameters\n\nworkspace (Workspace | str) – ID or model of the workspace.\n\n\n\nget(id: str | None = None, name: str | None = None) -> Workspace\n\nGet a specific workspace object from the server by either ID or name.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the workspace.\n\nname (str | None) – Name of the workspace.\n\nReturns\n\nWorkspace instance with the given ID if it exists\n\nRaises\n\nNotFoundError – No workspace with the given ID exists.\n\nReturn type\n\nWorkspace\n\n\n\nlist() -> List[Workspace]\n\nList all workspaces from the server.\n\n"},{"objectID":"API reference","href":"api_reference/workspaces.html#model","title":"API reference > Workspaces > Model","text":"Model\n\n\n\nclass Workspace\n\nProvides the local representation of a workspace object.\n\n\n\ndelete()\n\nDelete the workspace.\n\n\n\ndownload_mer_data(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the names, subsets and plotting data of the files used in the AI model and MER for the workspace.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\ndownload_model_evaluation_report(file: BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None = None) -> None | BinaryIO\n\nDownload the PDF of the model evaluation report for the workspace.\n\nParameters\n\nfile (BinaryIO | RawIOBase | BufferedIOBase | Path | str | PathLike | None) – Binary file-object or the path of the file to put the content into.\n\nReturns\n\nNone if a file is specified or a binary file-object otherwise.\n\nReturn type\n\nNone | BinaryIO\n\n\n\nlist_geometries() -> List[Geometry]\n\nLists all the geometries in the workspace.\n\n\n\n\n\nlist_predictions() -> List[Prediction]\n\nLists all the predictions in the workspace.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nrename(new_name: str) -> None\n\nRename the workspace.\n\nParameters\n\nnew_name (str) – New name to give to the workspace.\n\n\n\nset_as_current_workspace() -> None\n\nConfigure the client to use this workspace instead of the one currently configured.\n\n\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty model: ModelManifest\n\nDeprecated alias to model_manifest.\n\n\n\nproperty model_configuration: ModelConfiguration\n\nModel configuration used in the workspace.\n\n\n\nproperty model_manifest: ModelManifest\n\nModelManifest instance containing\ninformation about the model associated with the workspace.\n\n\n\nproperty name: str\n\nName of the workspace."},{"objectID":"API reference","href":"api_reference/workspaces.html#modelmanifest","title":"API reference > Workspaces > ModelManifest","text":"ModelManifest\n\n\n\nclass ModelManifest\n\nProvides information about a model associated with a workspace.\n\n\n\n\n\nproperty boundary_conditions: Dict[str, Any]\n\n(Deprecated) Information on the boundary conditions expected by the model. For example, the prediction’s input.\n\n\n\nproperty description: str\n\nShort description of the model.\n\n\n\nproperty geometry: Dict[str, Any]\n\nInformation on the geometry format expected by the model.\n\n\n\nproperty name: str\n\nName of the model.\n\n\n\nproperty physical_quantities: Dict[str, Any]\n\nInformation on the physical quantities generated by the model. For example, the prediction’s output.\n\n\n\nproperty post_processings: List[Dict[str, Any]]\n\nInformation on the postprocessings available for the model\nand the accepted parameters when relevant.\n\n\n\nproperty scalars: Dict[str, Any]\n\nInformation on the scalars expected by the model. For example, the prediction’s input."},{"objectID":"Home","href":"_examples/01_pysimai_ex/01-model_recomputation.html#model-recomputation","title":"Model recomputation","text":"Model recomputation\n\nThis example demonstrates how to relaunch a model build using the latest\nmodel configuration in a same project."},{"objectID":"Home","href":"_examples/01_pysimai_ex/01-model_recomputation.html#import-necessary-libraries","title":"Model recomputation > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/01_pysimai_ex/01-model_recomputation.html#get-the-project-from-the-server","title":"Model recomputation > Get the project from the server","text":"Get the project from the server"},{"objectID":"Home","href":"_examples/01_pysimai_ex/01-model_recomputation.html#get-the-model-configuration","title":"Model recomputation > Get the model configuration","text":"Get the model configuration\n\nGet the latest model configuration of the project."},{"objectID":"Home","href":"_examples/01_pysimai_ex/01-model_recomputation.html#verify-the-project-requirements","title":"Model recomputation > Verify the project requirements","text":"Verify the project requirements\n\nVerify that the project meets the requirements for training (model building).\n\nIf the project met the requirements, launch a model build.\nOtherwise, print the reasons the project does not meet the requirements.\n\n\n\nDownload Jupyter notebook: 01-model_recomputation.ipynb\n\nDownload Python source code: 01-model_recomputation.py\n\nDownload zipped: 01-model_recomputation.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"API reference","href":"api_reference/model_configuration.html#model-configuration","title":"API reference > Model configuration","text":"Model configuration\n\n\n\nThis module contains a collection of classes for creating a model configuration.\nThe model configuration defines the model’s inputs, outputs, Global Coefficients,\nbuild duration and project. The resulting\n(ModelConfiguration)\nobject is subsequently used to train a model."},{"objectID":"API reference","href":"api_reference/model_configuration.html#globalcoefficientdefinition","title":"API reference > Model configuration > GlobalCoefficientDefinition","text":"GlobalCoefficientDefinition\n\n\n\nclass GlobalCoefficientDefinition\n\nGlobal coefficient definition/parameter field.\n\nParameters\n\nformula (str) – Global Coefficient formula.\n\nname (str) – Global Coefficient name.\n\ngc_location (Literal['cells', 'points']) – Location of the Global Coefficient"},{"objectID":"API reference","href":"api_reference/model_configuration.html#domainaxisdefinition","title":"API reference > Model configuration > DomainAxisDefinition","text":"DomainAxisDefinition\n\n\n\nclass DomainAxisDefinition\n\nDefines an axis in the Domain of Analysis.\n\nParameters\n\nposition (Literal['relative_to_min', 'relative_to_max', 'relative_to_center', 'absolute']) – Anchor point position.relative_to_min: VolXmin = xmin - valuerelative_to_max: VolXmax = xmax + valuerelative_to_center: (xmin+xmax)/2 - valueabsolute: VolXmin = value\n\nvalue (float) – Distance of the anchor from the position.\nWhen position=absolute, the distance can be either positive or negative.\nIn any other case, only positive values are accepted.\n\nlength (float) – Length of the Domain of Analysis along the axis. Only positive numbers are accepted.\n\nExample\n\nDefine the Z-axis(i.e., height) in a Domain of Analysis"},{"objectID":"API reference","href":"api_reference/model_configuration.html#domainofanalysis","title":"API reference > Model configuration > DomainOfAnalysis","text":"DomainOfAnalysis\n\n\n\nclass DomainOfAnalysis\n\nDefines the Domain of Analysis.\n\nParameters\n\nlength (DomainAxisDefinition) – Domain of Analysis along the X axis\n\nwidth (DomainAxisDefinition) – Domain of Analysis along the Y axis\n\nheight (DomainAxisDefinition) – Domain of Analysis along the Z axis\n\nExample\n\nGet the Domain of Analysis from a configuration and replace it with a new one"},{"objectID":"API reference","href":"api_reference/model_configuration.html#modelinput","title":"API reference > Model configuration > ModelInput","text":"ModelInput\n\n\n\nclass ModelInput\n\nModel inputs.\n\nParameters\n\nsurface (list[str]) – Input surface variables.\n\nscalars (list[str]) – Input Scalars.\n\nboundary_conditions (list[str]) – (Deprecated) Input Scalars."},{"objectID":"API reference","href":"api_reference/model_configuration.html#modeloutput","title":"API reference > Model configuration > ModelOutput","text":"ModelOutput\n\n\n\nclass ModelOutput\n\nThe outputs of a model.\n\nParameters\n\nsurface (list[str]) – the output surface variables.\n\nvolume (list[str]) – the output volume variables.\n\nscalars (list[str]) – the output scalars."},{"objectID":"API reference","href":"api_reference/model_configuration.html#modelconfiguration","title":"API reference > Model configuration > ModelConfiguration","text":"ModelConfiguration\n\n\n\nclass ModelConfiguration\n\nConfigures the build of a model.\n\nbuild_on_top parameter is deprecated.\n\nParameters\n\nproject (Project) – the project of the configuration.\n\nbuild_preset (str | None) – indicates the build duration. Available options:debug: < 30 min, only 4 dat1_day: < 24 hours2_days: < 2 days, default value.7_days: < 1 week\n\nbuild_on_top (bool) – (Deprecated) indicates if build_on_top learning is enabled. Default is False.\n\ninput (ModelInput | None) – the inputs of the model.\n\noutput (ModelOutput | None) – the outputs of the model.\n\nglobal_coefficients (list[GlobalCoefficientDefinition] | None) – the Global Coefficients of the model.\n\ndomain_of_analysis (DomainOfAnalysis | None) – The Domain of Analysis of the model configuration.\n\npp_input (PostProcessInput | None) – The post-processing input (e.g. a surface variable).\n\nExample\n\nDefine a new configuration and launch a build.\n\nSets the properties of a build configuration.\n\n\n\ncompute_global_coefficient() -> List[float]\n\nComputes the results of the formula for all global coefficients with respect to the project’s sample.\n\n"},{"objectID":"API reference","href":"api_reference/model_configuration.html#postprocessinput","title":"API reference > Model configuration > PostProcessInput","text":"PostProcessInput\n\n\n\nclass PostProcessInput\n\nDesignates the variables to use as post-processing input.\n\nParameters\n\nsurface (list[str]) – the post-processing input surface variables."},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#client-configuration","title":"User guide > Client configuration","text":"Client configuration"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#where-to-start","title":"User guide > Client configuration > Where to start","text":"Where to start\n\nYou start by creating a SimAIClient\ninstance:\n\nAs demonstrated in the preceding code, you configure the instance by\npassing the required parameters on client creation. You are prompted\nfor any missing parameters.\n\nOnce you understand how creating an instance works, you can look into using a\nconfiguration file for creating a client instance."},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#configuration-options","title":"User guide > Client configuration > Configuration options","text":"Configuration options\n\nDescriptions follow of all configuration options for the SimAIClient\nclass:\n\n\n\npydantic model ClientConfig\n\nCreate a new model by parsing and validating input data from keyword arguments.\n\nRaises [ValidationError][pydantic_core.ValidationError] if the input data cannot be\nvalidated to form a valid model.\n\nself is explicitly positional-only to allow self as a field name.\n\n\n\nfield credentials: Credentials | None = None\n\nAuthenticate via username/password instead of the device authorization code.\n\n\n\nfield geomai_project: str | None = None\n\nName of the GeomAI project to use by default.\n\n\n\nfield geomai_workspace: str | None = None\n\nName of the GeomAI workspace to use by default.\n\n\n\nfield https_proxy: AnyHttpUrl | None = None\n\nURL of the HTTPS proxy to use.\n\n\n\nfield interactive: bool | None = True\n\nIf True, it enables interaction with the terminal.\n\n\n\nfield no_sse_connection: bool = False\n\nDon’t receive live updates from the SimAI API.\n\n\n\nfield offline_token: str | None = None\n\nAuthenticate via an offline token instead of credentials or device auth.\n\n\n\nfield organization: str = None\n\nName of the organization(/company) that the user belongs to.\n\n\n\nfield project: str | None = None\n\nName of the project to use by default.\n\n\n\nfield skip_version_check: bool = False\n\nSkip checking for updates.\n\n\n\nfield tls_ca_bundle: Literal['system', 'unsecure-none'] | PathLike | None = None\n\nCustom TLS CA certificate configuration. Possible values:\n\nNone: use secure defaults\n\n\"system\": uses system CA certificates (python >= 3.10)\n\nA PathLike object: use a custom CA\n\n\"unsecure-none\": no TLS certificate validation\n\n\n\nfield url: HttpUrl = HttpUrl('https://api.simai.ansys.com/v2/')\n\nURL to the SimAI API.\n\n\n\nfield workspace: str | None = None\n\nName of the workspace to use by default.\n\n"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#credentials","title":"User guide > Client configuration > Credentials","text":"Credentials\n\nTo use the SimAI API, your SimAIClient\ninstance must be authenticated. By default, you are prompted to log in\nvia your web browser. However, you can pass your credentials as parameters\non client creation:"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#credential-options","title":"User guide > Client configuration > Credential options","text":"Credential options\n\nDescriptions follow of all credential options for the SimAIClient\nclass:\n\n\n\npydantic model Credentials\n\nCreate a new model by parsing and validating input data from keyword arguments.\n\nRaises [ValidationError][pydantic_core.ValidationError] if the input data cannot be\nvalidated to form a valid model.\n\nself is explicitly positional-only to allow self as a field name.\n\nFields\n\npassword (str)\n\ntotp (str | None)\n\nusername (str)\n\n\n\nfield password: str [Required]\n\nPassword: Required if Credentials is defined, automatically prompted.\n\n\n\nfield totp: str | None = None\n\nOne-time password: required if totp_enabled=True, automatically prompted.\n\n\n\nfield username: str [Required]\n\nUsername: Required if Credentials is defined, automatically prompted.\n\n"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#interactive-mode","title":"User guide > Client configuration > Interactive mode","text":"Interactive mode\n\nWhen the property interactive is set to true, the users are prompted for the missing configuration\nproperties.\nWhen the property is false, the interactive mode is turned off, and errors would be raised\nin case of missing configuration properties.\nDefault behavior is interactive=true.\n\nIt is important to note that login through web browser is turned off when interactive=false.\nThis means that either credentials or offline_token must be provided, otherwise\nan error would be raised.\n\n"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#offline-tokens","title":"User guide > Client configuration > Offline tokens","text":"Offline tokens\n\nOffline tokens are long-lived authentication tokens that can be used for non-interactive\nauthentication. Unlike regular session tokens, offline tokens do not expire based on session\ntimeouts, making them ideal for server-side scripts, CI/CD pipelines, and automated workflows."},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#generating-an-offline-token","title":"User guide > Client configuration > Generating an offline token","text":"Generating an offline token\n\nYou can generate an offline token using an authenticated client:\n\nStore your offline token securely. It provides full access to your account\nand should be treated like a password."},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#using-an-offline-token","title":"User guide > Client configuration > Using an offline token","text":"Using an offline token\n\nOnce you have an offline token, you can use it for non-interactive authentication:\n\nOr in a configuration file:"},{"objectID":"User guide","href":"user_guide/configuration_guide/configuration.html#managing-consents","title":"User guide > Client configuration > Managing consents","text":"Managing consents\n\nConsents are the authorization records that grant a client (like the SDK) permission\nto use offline tokens. You can list and revoke consents through the client:\n\nYou cannot use both credentials and offline_token at the same time.\nChoose one authentication method."},{"objectID":"API reference","href":"api_reference/optimizations.html#optimization","title":"API reference > Optimization","text":"Optimization\n\n"},{"objectID":"API reference","href":"api_reference/optimizations.html#directory","title":"API reference > Optimization > Directory","text":"Directory\n\n\n\nclass OptimizationDirectory\n\nProvides a collection of methods related to optimizations.\n\nThis class is accessed through client.optimizations.\n\nExample\n\n\n\n\n\nget(optimization_id: str) -> Optimization\n\nGet a specific optimization object from the server.\n\nParameters\n\noptimization_id (str) – ID of the optimization.\n\nReturns\n\nOptimization.\n\nReturn type\n\nOptimization\n\n\n\nrun_non_parametric(geometry: Geometry | str, bounding_boxes: List[List[float]], n_iters: int, symmetries: List[Literal['x', 'y', 'z', 'X', 'Y', 'Z']] | None = None, axial_symmetry: Literal['x', 'y', 'z'] | None = None, scalars: Dict[str, float] | None = None, minimize: List[str] | None = None, maximize: List[str] | None = None, max_displacement: List[float] | None = None, show_progress: bool = False, boundary_conditions: Dict[str, float] | None = None) -> OptimizationResult\n\nRun an optimization loop to generate geometries, server-side, using automorphing.\nAutomorphing is a non-parametric deformation of a surface geometry.\n\nParameters\n\ngeometry (Geometry | str) – Required. The object (Geometry) or the ID (str) of the baseline geometry on which to perform\nthe non-parametric optimization and that has already been used to build an AI model.\nThe optimization will run in the same workspace as the model.\n\nbounding_boxes (List[List[float]]) – Required. The list of the bounds of the different boxes that will define the absolute locations\nof the geometry to optimize. It is a list of lists, and each sub-list must have exactly six items with the following\nexpected order: [x_min, x_max, y_min, y_max, z_min, z_max].Example format:\n\nn_iters (int) – Required. The number of optimization iterations. This number must be a strictly positive integer.\nIt will define the number of automorphed geometries uploaded to the SimAI workspace.\n\nsymmetries (List[Literal['x', 'y', 'z', 'X', 'Y', 'Z']] | None) – Optional. The list of symmetry axes, axes being x, y, and z, defining a plane around which the geometry is mirrored.The planar symmetry is applied to all the bounding_boxes defined.\n\nsymmetries and axial_symmetry are mutually exclusive parameters.\n\naxial_symmetry (Literal['x', 'y', 'z'] | None) – Optional. The axis, defined by a scalar, along which axial symmetry is applied.\nFor the deformation to be axially symmetrical:The center of the bounding box must coincide with the targeted central axis.\n\nThe mesh should be axially symmetrical in the bounding box.\n\nThe axial_symmetry is applied to all the bounding_boxes defined.\n\nsymmetries and axial_symmetry are mutually exclusive parameters.\n\nscalars (Dict[str, float] | None) – Optional. The values of the scalars to perform the optimization at.\nThe values must correspond to existing scalars already defined in your SimAI workspace.\n\nminimize (List[str] | None) – Required if no maximize parameter is defined. A list of one global coefficient to minimize.\nThis global coefficient must correspond to one of the existing coefficients defined in your model configuration.\n\nmaximize (List[str] | None) – Required if no minimize parameter is defined. A list of one global coefficient to maximize.\nThis global coefficient must correspond to one of the existing coefficients defined in your model configuration.minimize and maximize are mutually exclusive objectives; define only one.\n\nThe defined objective must be computed from the surface fields because mesh nodes must be involved.\n\nmax_displacement (List[float] | None) – Optional. User-defined constraint on the maximum allowable deformation of the initial mesh in non-parametric optimization.\nIt is specified as a list (max_displacement) matching the number of bounding boxes (bounding_boxes).For example, for two bounding boxes:bounding_boxes = [[0,1,0,2,0,4],[10,2,10,4,10,5]]\n\nmax_displacement = [0.002, 0.001]Each value limits the displacement within the corresponding bounding box, using the same metric as the bounding box coordinates.\n\nshow_progress (bool) – Optional. Whether to print progress bar on stdout.\nIt is updated each time a new iteration is completed.\n\nboundary_conditions (Dict[str, float] | None) – Optional. (Deprecated) The values of the boundary conditions to perform the optimization at.\nThe values must correspond to existing boundary conditions already defined in your SimAI workspace.\n\nExample\n\nReturns\n\nAn object containing the results of the optimization.\n\nReturn type\n\nOptimizationResult"},{"objectID":"API reference","href":"api_reference/optimizations.html#model","title":"API reference > Optimization > Model","text":"Model\n\n\n\nclass Optimization\n\nProvides the local representation of an optimization definition object.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nwait(timeout: float | None = None) -> bool\n\nWait for all jobs concerning the object to either finish\nor fail.\n\nParameters\n\ntimeout (float | None) – Maximum amount of time in seconds to wait. The default is\nNone, it means that there is no maximum on the time to wait.\n\nReturns\n\nTrue if the computation has finished, False if the operation timed out.\n\nReturn type\n\nbool\n\n\n\nproperty failure_reason\n\nOptional message giving the causes for why the\ncreation of the object failed.\n\nhas_failed\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty has_failed\n\nBoolean indicating if the creation of the object failed.\n\nfailure_reason\n\nwait()\n\nis_ready\n\nis_pending\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty is_pending\n\nBoolean indicating if the object is still in creation.\nThe value becomes False once object creation is either successful\nor has failed.\n\nwait()\n\nis_ready\n\nhas_failed\n\n\n\nproperty is_ready\n\nBoolean indicating if the object has finished creating without error.\n\nwait()\n\nis_pending\n\nhas_failed\n\n\n\nclass OptimizationResult\n\nResult for a non-parametric optimization.\n\n\n\n\n\nlist_geometries() -> List[Geometry]\n\nList of geometries generated by the optimization.\n\n\n\n\n\nlist_objectives() -> List[Dict]\n\nList of objectives generated by the optimization.\n\n\n\n\n\nproperty optimization: Optimization\n\nOptimization object of the optimization run."},{"objectID":"Home","href":"_examples/02_generative_design_ex/sg_execution_times.html#computation-times","title":"Computation times","text":"Computation times\n\n00:00.000 total execution time for 4 files from _examples/02_generative_design_ex:\n\n\n\n\n\n\n\nExample\n\nTime\n\nMem (MB)\n\nsphx_glr__examples_02_generative_design_ex_00-create_project_upload_data.py (00-create_project_upload_data.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_01-build_model.py (01-build_model.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_02-generate_random_geometries.py (02-generate_random_geometries.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_02_generative_design_ex_03-interpolate_geometries.py (03-interpolate_geometries.py)\n\n00:00.000\n\n0.0"},{"objectID":"API reference","href":"api_reference/global_coefficients_requests.html#global-coefficients","title":"API reference > Global coefficients","text":"Global coefficients\n\n\n\nThis module contains a collection of classes for validating global coefficient formulas and\nexecuting them on project samples."},{"objectID":"API reference","href":"api_reference/global_coefficients_requests.html#processglobalcoefficient","title":"API reference > Global coefficients > ProcessGlobalCoefficient","text":"ProcessGlobalCoefficient\n\n\n\nclass ProcessGlobalCoefficient\n\nProcesses the result of a Global Coefficient formula.\nHandles the check and compute requests in a single call.\n\n\n\n\n\nrun() -> None\n\nPerforms a process-formula request.\n\n\n\n\n\nproperty result: float | None\n\nGet the result of the Global Coefficient formula."},{"objectID":"API reference","href":"api_reference/global_coefficients_requests.html#processglobalcoefficientdirectory","title":"API reference > Global coefficients > ProcessGlobalCoefficientDirectory","text":"ProcessGlobalCoefficientDirectory\n\n\n\nclass ProcessGlobalCoefficientDirectory\n\nExtends GlobalCoefficientRequestDirectory for computing the result of a Global Coefficient formula.\n\n"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#running-physics-predictions","title":"Running Physics Predictions","text":"Running Physics Predictions\n\nThis example demonstrates how to upload geometries to a workspace and run predictions\nusing a trained SimAI model. It also shows how to extract and save prediction results,\nincluding global coefficients and confidence scores."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#before-you-begin","title":"Running Physics Predictions > Before you begin","text":"Before you begin\n\nComplete “ref_basic_build_model” to train a SimAI model.\n\nEnsure the model training completed successfully.\n\nHave a dataset folder with subdirectories containing geometry files. These geometry files can come from a Generative Design model.\n\n(Optional) Prepare boundary condition JSON files if your model requires them."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#import-necessary-libraries","title":"Running Physics Predictions > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#configure-your-settings","title":"Running Physics Predictions > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#initialize-the-client-and-set-workspace","title":"Running Physics Predictions > Initialize the client and set workspace","text":"Initialize the client and set workspace\n\nConnect to SimAI and set the workspace to use for predictions:\n\nSet the current workspace:\n\nA workspace contains a trained model and is created when a model build completes successfully."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#prepare-data-structures","title":"Running Physics Predictions > Prepare data structures","text":"Prepare data structures\n\nCreate lists to store geometries and their boundary conditions:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#upload-geometries-and-load-boundary-conditions","title":"Running Physics Predictions > Upload geometries and load boundary conditions","text":"Upload geometries and load boundary conditions\n\nProcess each subdirectory in the dataset:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#run-predictions-on-all-geometries","title":"Running Physics Predictions > Run predictions on all geometries","text":"Run predictions on all geometries\n\nWait for all geometries to be processed, then run predictions:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#collect-prediction-results","title":"Running Physics Predictions > Collect prediction results","text":"Collect prediction results\n\nWait for all predictions to complete and extract results:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#save-results-to-file","title":"Running Physics Predictions > Save results to file","text":"Save results to file\n\nExport all prediction results to a JSON file for further analysis:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#understanding-the-results","title":"Running Physics Predictions > Understanding the results","text":"Understanding the results\n\nThe results dictionary contains:\n\nGlobal coefficients: Scalar values computed from the prediction,\n\nConfidence score: A measure of how familiar this prediction is for the model.\n\nYou can also download full field results (VTP files) for visualization:\n\nUse pred.post.surface_vtp() to get surface fields.\n\nUse pred.post.volume_vtu() to get volume fields."},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#example-download-surface-vtp-for-visualization","title":"Running Physics Predictions > Example: Download surface VTP for visualization","text":"Example: Download surface VTP for visualization\n\nRun the following code to download the first prediction’s surface VTP:"},{"objectID":"Home","href":"_examples/00_basic_simai_ex/02-run_predictions.html#next-steps","title":"Running Physics Predictions > Next steps","text":"Next steps\n\nWith your prediction results, you can:\n\nAnalyze global coefficients to evaluate design performance.\n\nVisualize field results in ParaView or similar tools.\n\nCompare predictions against validation data.\n\nUse results to guide design optimization.\n\n\n\nDownload Jupyter notebook: 02-run_predictions.ipynb\n\nDownload Python source code: 02-run_predictions.py\n\nDownload zipped: 02-run_predictions.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#generating-random-geometries","title":"Generating Random Geometries","text":"Generating Random Geometries\n\nThis example demonstrates how to generate random geometries using random latent parameters."},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#before-you-begin","title":"Generating Random Geometries > Before you begin","text":"Before you begin\n\nComplete “ref_build_model” to train a Generative Design model.\n\nEnsure the model training completed successfully."},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#import-necessary-libraries","title":"Generating Random Geometries > Import necessary libraries","text":"Import necessary libraries"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#configure-your-settings","title":"Generating Random Geometries > Configure your settings","text":"Configure your settings\n\nUpdate these variables with your specific settings:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#initialize-the-client-and-get-the-workspace","title":"Generating Random Geometries > Initialize the client and get the workspace","text":"Initialize the client and get the workspace\n\nConnect to the instance:\n\nRetrieve the trained workspace by its name:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#get-the-number-of-latent-parameters","title":"Generating Random Geometries > Get the number of latent parameters","text":"Get the number of latent parameters\n\nThe number of latent parameters is defined during model training:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#create-output-directory","title":"Generating Random Geometries > Create output directory","text":"Create output directory\n\nCreate a directory to save the generated geometries:"},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#generate-random-geometries","title":"Generating Random Geometries > Generate random geometries","text":"Generate random geometries\n\nGenerate geometries by creating random latent parameter vectors.\nEach latent parameter is randomly sampled from a standard normal distribution."},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#download-generated-geometries","title":"Generating Random Geometries > Download generated geometries","text":"Download generated geometries\n\nThe downloaded VTP files can be used for:\n\nVisualization in your usual solver.\n\nSimAI training data or predictions.\n\nFurther analysis and post-processing."},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#tips-for-better-results","title":"Generating Random Geometries > Tips for better results","text":"Tips for better results\n\nLatent parameters typically range from -3 to +3 for meaningful results.\n\nAdjust the resolution to balance quality and file size.\n\nIncrease timeout for complex geometries.\n\nUse the workspace’s latent space statistics (min, max) for better sampling."},{"objectID":"Home","href":"_examples/02_generative_design_ex/02-generate_random_geometries.html#next-steps","title":"Generating Random Geometries > Next steps","text":"Next steps\n\nTo generate geometries with more control, see ref_interpolate_geometries.\n\n\n\nDownload Jupyter notebook: 02-generate_random_geometries.ipynb\n\nDownload Python source code: 02-generate_random_geometries.py\n\nDownload zipped: 02-generate_random_geometries.zip\n\nGallery generated by Sphinx-Gallery"},{"objectID":"Home","href":"_examples/01_pysimai_ex/sg_execution_times.html#computation-times","title":"Computation times","text":"Computation times\n\n00:00.000 total execution time for 4 files from _examples/01_pysimai_ex:\n\n\n\n\n\n\n\nExample\n\nTime\n\nMem (MB)\n\nsphx_glr__examples_01_pysimai_ex_00-model_configuration_reuse.py (00-model_configuration_reuse.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_01-model_recomputation.py (01-model_recomputation.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_02-subset_assignment.py (02-subset_assignment.py)\n\n00:00.000\n\n0.0\n\nsphx_glr__examples_01_pysimai_ex_03-list_based_subset_assignment.py (03-list_based_subset_assignment.py)\n\n00:00.000\n\n0.0"},{"objectID":"API reference","href":"api_reference/projects.html#projects","title":"API reference > Projects","text":"Projects\n\n\n\n\n\nProjects are a selection of training data used to train a model."},{"objectID":"API reference","href":"api_reference/projects.html#directory","title":"API reference > Projects > Directory","text":"Directory\n\n\n\nclass ProjectDirectory\n\nProvides a collection of methods related to projects.\n\nThis class is accessed through client.projects.\n\nExample\n\nList all projects:\n\n\n\n\n\ncancel_build(project: Project | str)\n\nCancel a build if one is in progress.\n\nParameters\n\nproject (Project | str) – ID or model of the project.\n\n\n\ncreate(name: str) -> Project\n\nCreate a project.\n\n\n\n\n\ndelete(project: Project | str) -> None\n\nDelete a project.\n\nParameters\n\nproject (Project | str) – ID or model of the project.\n\n\n\nget(id: str | None = None, name: str | None = None) -> Project\n\nGet a project by either ID or name.\n\nYou can specify either the ID or the name, not both.\n\nParameters\n\nid (str | None) – ID of the project.\n\nname (str | None) – Name of the project.\n\nRaises\n\nansys.simai.core.errors.NotFoundError – If the project doesn’t exist\n\n\n\nlist() -> list[Project]\n\nList all projects available on the server.\n\n"},{"objectID":"API reference","href":"api_reference/projects.html#model","title":"API reference > Projects > Model","text":"Model\n\n\n\nclass Project\n\nProvides the local representation of a project object.\n\n\n\n\n\ncancel_build()\n\nCancels a build if there is one pending.\n\n\n\ndelete() -> None\n\nDelete the project.\n\n\n\n\n\nget_variables() -> dict[str, list[str]] | None\n\nGet the available variables for the model’s input/output.\n\n\n\n\n\nis_trainable() -> IsTrainableInfo\n\nCheck if the project meets the prerequisites to be trained.\n\n\n\n\n\nlist_models() -> list[Model]\n\nList of all Model instances in the project.\n\n\n\n\n\nlist_training_data() -> list[TrainingData]\n\nList of all TrainingData instances in the project.\n\n\n\n\n\nlist_workspaces() -> list[Workspace]\n\nLists all Workspace instances in the project.\n\n\n\n\n\nprocess_gc_formula(gc_formula: str, bc: list[str] = None, surface_variables: list[str] = None, gc_location: Literal['cells', 'points'] = 'cells') -> float | None\n\nProcess the formula of a global coefficient according to the project sample.\nIt handles checking and computing the global coefficient formula as one workflow.\n\n\n\n\n\nreload() -> None\n\nRefresh the object with its representation from the server.\n\n\n\n\n\nrename(new_name: str) -> None\n\nRename the project.\n\nParameters\n\nnew_name (str) – New name to give to the project.\n\n\n\nset_as_current_project() -> None\n\nConfigure the client to use this project instead of the one currently configured.\n\n\n\n\n\nproperty data: list[TrainingData]\n\n(Deprecated)List of all TrainingData instances in the project.\n\nUse list_training_data() instead.\n\n\n\nproperty fields: dict\n\nDictionary containing the raw object representation.\n\n\n\nproperty id: str\n\nID of the object on the server.\n\n\n\nproperty last_model_configuration: ModelConfiguration | None\n\nLast configuration used for model training in this project.\n\n\n\nproperty name: str\n\nName of project.\n\n\n\nproperty sample: TrainingData | None\n\nSample of the project. The sample determines what variable and settings are available during model configuration.\n\n\n\nproperty training_capabilities: TrainingCapabilities\n\nTraining capabilities of the project. Determines whether a project can use continuous learning."},{"objectID":"API reference","href":"api_reference/projects.html#istrainableinfo","title":"API reference > Projects > IsTrainableInfo","text":"IsTrainableInfo\n\n\n\nclass IsTrainableInfo\n\nProperties for project’s trainability.\n\nThe objects of this class can be used as booleans\nin condition statements as in the example:\n\nExample\n\nVerify the project is trainable\n\nIt prints:\n\n\n\n\n\nis_trainable\n\nTrue if the project is trainable, False if it is not.\n\nType\n\nbool\n\n\n\nreason\n\nIf not_trainable is False, the reason why the project is not trainable. None otherwise.\n\nType\n\nstr\n\nCreate new instance of IsTrainableInfo(is_trainable, reason)"},{"objectID":"API reference","href":"api_reference/projects.html#trainingcapabilities","title":"API reference > Projects > TrainingCapabilities","text":"TrainingCapabilities\n\n\n\nclass TrainingCapabilities\n\nProvides a project’s training capabilities.\n\nParameters\n\ncontinuous_learning (ContinuousLearningCapabilities) – Continuous learning capabilities."},{"objectID":"API reference","href":"api_reference/projects.html#continuouslearningcapabilities","title":"API reference > Projects > ContinuousLearningCapabilities","text":"ContinuousLearningCapabilities\n\n\n\nclass ContinuousLearningCapabilities\n\nProvides a project’s continuous learning capabilities.\n\nParameters\n\nable (bool) – Is this project able to use continuous learning feature\n\nreasons (list[str]) – Reasons why a project can’t use continuous learning feature"}]